{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f147e-5129-434d-ac0e-b91d147ac0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pydantic import BaseModel, Field, EmailStr\n",
    "from typing import List, Literal, Optional\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "import anthropic\n",
    "from dotenv import load_dotenv\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6376f52-7070-41c7-887b-69cf28abad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the UserInput model for customer support queries\n",
    "class UserInput(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "    query: str\n",
    "    order_id: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"5-digit order number (cannot start with 0)\",\n",
    "        ge=10000,\n",
    "        le=99999\n",
    "    )\n",
    "    purchase_date: Optional[date] = None\n",
    "\n",
    "# Define the CustomerQuery model that inherits from UserInput\n",
    "class CustomerQuery(UserInput):\n",
    "    priority: str = Field(\n",
    "        ..., description=\"Priority level: low, medium, high\"\n",
    "    )\n",
    "    category: Literal[\n",
    "        'refund_request', 'information_request', 'other'\n",
    "    ] = Field(..., description=\"Query category\")\n",
    "    is_complaint: bool = Field(\n",
    "        ..., description=\"Whether this is a complaint\"\n",
    "    )\n",
    "    tags: List[str] = Field(..., description=\"Relevant keyword tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e6b9b8-ddb5-486a-91bc-9655110c0616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your input data as a JSON string\n",
    "user_input_json = '''{\n",
    "    \"name\": \"Joe User\",\n",
    "    \"email\": \"joe.user@example.com\",\n",
    "    \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n",
    "    \"order_number\": 12345,\n",
    "    \"purchase_date\": \"2025-12-31\"\n",
    "}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54214e90-8485-4975-8fa8-af2c5a4bc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the user_input_json by creating a UserInput instance\n",
    "user_input = UserInput.model_validate_json(user_input_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2c906e-77db-4b67-8588-64b13b9ee6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    f\"Analyze the following customer query {user_input} \"\n",
    "    f\"and provide a structured response.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59368db1-14e5-4304-9be5-f018be3139fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "# # Use Anthropic with Instructor to get structured output\n",
    "# anthropic_client = instructor.from_anthropic(\n",
    "#     anthropic.Anthropic()\n",
    "# )\n",
    "\n",
    "# response = anthropic_client.messages.create(\n",
    "#     model=\"claude-3-7-sonnet-latest\",  \n",
    "#     max_tokens=1024,\n",
    "#     messages=[\n",
    "#         {\n",
    "#             \"role\": \"user\", \n",
    "#             \"content\": prompt\n",
    "#         }\n",
    "#     ],\n",
    "#     response_model=CustomerQuery  \n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f040e1-54d9-44d8-be47-9b24bed9875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect the returned structured data\n",
    "# print(type(response))\n",
    "# print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4754eab-c7d6-4e59-945f-3fccfadca577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "{\"name\":\"Joe User\",\"email\":\"joe.user@example.com\",\"query\":\"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\"order_id\":null,\"purchase_date\":null,\"priority\":\"high\",\"category\":\"refund_request\",\"is_complaint\":true,\"tags\":[\"damaged_product\",\"replacement\",\"urgent\"]}\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client and call passing CustomerQuery in your API call\n",
    "openai_client = OpenAI()\n",
    "response = openai_client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format=CustomerQuery\n",
    ")\n",
    "response_content = response.choices[0].message.content\n",
    "print(type(response_content))\n",
    "print(response_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdfaec-5280-4d33-97b0-734c76170767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CustomerQuery'>\n",
      "{\n",
      "  \"name\": \"Joe User\",\n",
      "  \"email\": \"joe.user@example.com\",\n",
      "  \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n",
      "  \"order_id\": null,\n",
      "  \"purchase_date\": null,\n",
      "  \"priority\": \"high\",\n",
      "  \"category\": \"refund_request\",\n",
      "  \"is_complaint\": true,\n",
      "  \"tags\": [\n",
      "    \"damaged_product\",\n",
      "    \"replacement\",\n",
      "    \"urgent\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Validate the repsonse you got from the LLM\n",
    "valid_data = CustomerQuery.model_validate_json(\n",
    "    response_content\n",
    ")\n",
    "print(type(valid_data))\n",
    "print(valid_data.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642cbfb4-fa1b-4507-8bde-1c3d2012a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'openai.types.responses.parsed_response.ParsedResponse[CustomerQuery]'>\n"
     ]
    }
   ],
   "source": [
    "# Try the responses API from OpenAI\n",
    "response = openai_client.responses.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    text_format=CustomerQuery\n",
    ")\n",
    "\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c0d366-82c4-4b02-8460-a0171f30128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai.types.responses.parsed_response.ParsedResponse[CustomerQuery]\n",
      "openai.types.responses.parsed_response.ParsedResponse\n",
      "openai.types.responses.response.Response\n",
      "openai._models.GenericModel\n",
      "openai._compat.GenericModel\n",
      "openai.BaseModel\n",
      "pydantic.main.BaseModel\n",
      "typing.Generic\n",
      "builtins.object\n"
     ]
    }
   ],
   "source": [
    "# Investigate class inheritance structure of the OpenAI response\n",
    "def print_class_inheritence(llm_response):\n",
    "    for cls in type(llm_response).mro():\n",
    "        print(f\"{cls.__module__}.{cls.__name__}\")\n",
    "\n",
    "print_class_inheritence(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc2473-3574-48ba-be56-29f9f3fb1e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.CustomerQuery'>\n",
      "{\n",
      "  \"name\": \"Joe User\",\n",
      "  \"email\": \"joe.user@example.com\",\n",
      "  \"query\": \"I ordered a new computer monitor and it arrived with the screen cracked. This is the second time this has happened. I need a replacement ASAP.\",\n",
      "  \"order_id\": null,\n",
      "  \"purchase_date\": \"2025-12-31\",\n",
      "  \"priority\": \"high\",\n",
      "  \"category\": \"refund_request\",\n",
      "  \"is_complaint\": true,\n",
      "  \"tags\": [\n",
      "    \"monitor\",\n",
      "    \"damaged\",\n",
      "    \"replacement\",\n",
      "    \"urgent\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the response type and content \n",
    "print(type(response.output_parsed))\n",
    "print(response.output_parsed.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57af97a-6608-4d80-aea7-533306687ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out the Pydantic AI package for defining an agent and getting a structured response\n",
    "from pydantic_ai import Agent\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# agent = Agent(\n",
    "#     model=\"google-gla:gemini-2.0-flash\",\n",
    "#     output_type=CustomerQuery,\n",
    "# )\n",
    "\n",
    "# response = agent.run_sync(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b4fcd-ddd0-4b46-813b-52576c89e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print out the repsonse type and content\n",
    "# print(type(response.output))\n",
    "# print(response.output.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
