{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076797b3",
   "metadata": {},
   "source": [
    "## 第07讲：图像切分不合理？文本图像矫正和版面区域检测保障信息完整且不冗余\n",
    "\n",
    "## 一、问题背景\n",
    "\n",
    "\n",
    "在上一讲中，我们介绍了 PaddleOCR 强大的图像识别能力和表格文字抽取能力。\n",
    "\n",
    "但有时我们并不想使用完整的 OCR 流程，而是希望利用其中的某些模块来增强自己的系统。\n",
    "\n",
    "比如：\n",
    "> “我已经有自己偏好的 OCR 工具了，但对 PaddleOCR 的图像预处理能力很感兴趣。”\n",
    "\n",
    "PaddleOCR 并不仅仅是一个整体 OCR 工具包，它还提供了多个可独立调用的功能模块，例如：\n",
    "\n",
    "- ✅ 文本图像矫正（Text Image Unwarping）\n",
    "- ✅ 版面区域检测（Layout Detection）\n",
    "\n",
    "这两个模块可以有效提升图像质量、定位关键区域、避免冗余信息干扰，是构建高质量 OCR 系统的重要组成部分。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d8810d",
   "metadata": {},
   "source": [
    "## 二、版面区域检测模块详解\n",
    "\n",
    "### 2.1 什么是版面区域检测？\n",
    "\n",
    "[版面区域检测](https://paddlepaddle.github.io/PaddleX/latest/module_usage/tutorials/ocr_modules/layout_detection.html#_2)\n",
    "的核心任务是对输入的文档图像进行内容解析和区域划分。通过识别图像中的不同元素（如文字、图表、图像、公式、段落、摘要、参考文献等），将其归类为预定义的类别，并确定这些区域在文档中的位置。\n",
    "\n",
    "这一步对于后续的 OCR 识别、信息抽取、结构化输出等环节至关重要，能够有效提升整体识别的准确性和逻辑性。\n",
    "\n",
    "\n",
    "\n",
    "### 2.2 支持的模型与类别\n",
    "\n",
    "PaddleOCR 提供了多种版面检测模型，支持多达 **23个常见类别**，包括但不限于：\n",
    "\n",
    "- 文档标题、段落标题  \n",
    "- 文本、页码、摘要  \n",
    "- 目录、参考文献、脚注  \n",
    "- 页眉、页脚、算法  \n",
    "- 公式、公式编号  \n",
    "- 图像、表格、图和表标题  \n",
    "- 印章、图表、侧栏文本  \n",
    "\n",
    "#### 支持模型列表（部分）：\n",
    "\n",
    "| 模型 | mAP(0.5) (%) | GPU推理耗时 (ms) | CPU推理耗时 (ms) | 模型大小 (MB) | 描述 |\n",
    "|------|---------------|------------------|------------------|---------------|------|\n",
    "| PP-DocLayout-L | 90.4 | 34.62 / 10.39 | 510.57 / - | 123.76 | 高精度版面区域定位模型 |\n",
    "| PP-DocLayout-M | 75.2 | 13.33 / 4.87 | 44.07 / 44.07 | 22.58 | 精度效率平衡模型 |\n",
    "| PP-DocLayout-S | 70.9 | 8.30 / 2.38 | 10.06 / 9.93 | 4.83 | 高效率模型 |\n",
    "\n",
    "完整模型列表详见官方文档。\n",
    "\n",
    "\n",
    "\n",
    "### 2.3 示例代码演示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b425e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rag50/lib/python3.12/site-packages/paddle/utils/cpp_extension/extension_utils.py:715: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (PP-DocLayout_plus-L), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2af47f8b3d645419d79c7757e01da69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/image_good.png', 'page_index': None, 'boxes': [{'cls_id': 2, 'label': 'text', 'score': 0.9845171570777893, 'coordinate': [np.float32(90.02504), np.float32(149.24373), np.float32(541.56226), np.float32(323.24805)]}, {'cls_id': 1, 'label': 'image', 'score': 0.9734574556350708, 'coordinate': [np.float32(106.04124), np.float32(329.02234), np.float32(543.95496), np.float32(527.4854)]}, {'cls_id': 2, 'label': 'text', 'score': 0.972456157207489, 'coordinate': [np.float32(614.44977), np.float32(338.04285), np.float32(1020.8649), np.float32(408.39597)]}, {'cls_id': 2, 'label': 'text', 'score': 0.9719167947769165, 'coordinate': [np.float32(598.0112), np.float32(138.84532), np.float32(1019.111), np.float32(228.49037)]}, {'cls_id': 7, 'label': 'formula', 'score': 0.9527032971382141, 'coordinate': [np.float32(623.0048), np.float32(81.488174), np.float32(1005.11096), np.float32(122.09485)]}, {'cls_id': 7, 'label': 'formula', 'score': 0.9476105570793152, 'coordinate': [np.float32(765.8002), np.float32(286.07346), np.float32(873.85785), np.float32(316.7914)]}, {'cls_id': 2, 'label': 'text', 'score': 0.9449989199638367, 'coordinate': [np.float32(614.55884), np.float32(480.60858), np.float32(1018.3273), np.float32(512.9662)]}, {'cls_id': 2, 'label': 'text', 'score': 0.9378035664558411, 'coordinate': [np.float32(607.3306), np.float32(231.58488), np.float32(1020.55634), np.float32(265.71686)]}, {'cls_id': 7, 'label': 'formula', 'score': 0.9363557696342468, 'coordinate': [np.float32(780.86694), np.float32(429.20782), np.float32(865.1085), np.float32(459.08353)]}, {'cls_id': 2, 'label': 'text', 'score': 0.8939992785453796, 'coordinate': [np.float32(91.238686), 0, np.float32(535.6037), np.float32(113.85552)]}, {'cls_id': 2, 'label': 'text', 'score': 0.8875880241394043, 'coordinate': [np.float32(594.28345), 0, np.float32(1013.56696), np.float32(70.756645)]}, {'cls_id': 7, 'label': 'formula', 'score': 0.8852363228797913, 'coordinate': [np.float32(701.07916), np.float32(529.37836), np.float32(939.6103), np.float32(542.9136)]}, {'cls_id': 0, 'label': 'paragraph_title', 'score': 0.8720102906227112, 'coordinate': [np.float32(90.56022), np.float32(129.25659), np.float32(279.69485), np.float32(144.38687)]}, {'cls_id': 6, 'label': 'figure_title', 'score': 0.8457791805267334, 'coordinate': [np.float32(112.7932), np.float32(533.2203), np.float32(553.12695), np.float32(583.8464)]}, {'cls_id': 3, 'label': 'number', 'score': 0.8426660895347595, 'coordinate': [np.float32(809.6771), np.float32(609.59357), np.float32(832.4501), np.float32(620.9446)]}, {'cls_id': 2, 'label': 'text', 'score': 0.8393117785453796, 'coordinate': [np.float32(617.0033), np.float32(564.9501), np.float32(755.95386), np.float32(579.2233)]}, {'cls_id': 3, 'label': 'number', 'score': 0.8025864362716675, 'coordinate': [np.float32(332.61142), np.float32(615.831), np.float32(359.80164), np.float32(628.5435)]}, {'cls_id': 7, 'label': 'formula', 'score': 0.5265483856201172, 'coordinate': [np.float32(457.79227), np.float32(533.7734), np.float32(487.2409), np.float32(549.3513)]}, {'cls_id': 7, 'label': 'formula', 'score': 0.516582727432251, 'coordinate': [np.float32(115.29364), np.float32(549.49054), np.float32(149.99469), np.float32(569.8837)]}]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 能正确识别的图像\n",
    "\n",
    "from paddleocr import LayoutDetection\n",
    "\n",
    "model = LayoutDetection(model_name=\"PP-DocLayout_plus-L\")\n",
    "output = model.predict(\"./pics/image_good.png\", batch_size=1, layout_nms=True)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./output07/\")\n",
    "    res.save_to_json(save_path=\"./output07/res.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b29cac5",
   "metadata": {},
   "source": [
    "### 这段代码的主要功能是？\n",
    "\n",
    "该代码调用的是 PaddleOCR 提供的 **版面区域检测模块**，用于对输入文档图像进行布局分析。具体功能包括：\n",
    "\n",
    "- 使用指定模型（如 `PP-DocLayout_plus-L`）对图像进行推理预测；\n",
    "- 输出每个检测到的区域及其类别标签、置信度和边界框坐标；\n",
    "- 将检测结果可视化为图像文件；\n",
    "- 将检测结果保存为 JSON 格式，便于后续处理与集成。\n",
    "\n",
    "### 它为我们解决的问题是？\n",
    "\n",
    "在实际 OCR 应用中，原始图像可能存在多个不同类型的内容区域（如表格、文本、图像、公式等）。如果直接对整张图进行识别，容易导致：\n",
    "\n",
    "- 信息混杂、识别混乱；\n",
    "- 多余区域干扰主内容识别；\n",
    "- 后续结构化提取困难。\n",
    "\n",
    "而通过版面区域检测模块，我们可以：\n",
    "\n",
    "✅ 精准定位图像中的各个内容区域  \n",
    "✅ 对不同类型的区域进行分类管理（如表格、文本、图像等）  \n",
    "✅ 避免冗余信息干扰，提高 OCR 的准确率和结构化输出效率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473ef95d",
   "metadata": {},
   "source": [
    "上面我们介绍了 PaddleOCR 的版面区域检测模块，它可以帮助我们精准地识别结构清晰、排版良好的文档图像。\n",
    "\n",
    "但是，现实中的图像并不总是“规规矩矩”的。比如：\n",
    "\n",
    "- 文档被拍摄时发生了**倾斜**；\n",
    "- 纸张有**弯曲、褶皱**；\n",
    "- 存在**透视变形**（比如从侧面拍照）；\n",
    "- 图像**模糊**或有**扭曲现象**。\n",
    "\n",
    "这些情况都会严重影响 OCR 的识别效果，甚至导致完全无法识别。\n",
    "\n",
    "这时，我们就需要引入 PaddleOCR 中的另一个强大模块 —— **文本图像矫正模块**。\n",
    "\n",
    "---\n",
    "\n",
    "## 3.1 文本图像矫正模块\n",
    "\n",
    "文本图像矫正如其名，它的主要目的是对图像进行**几何变换**，以纠正其中文档的**扭曲、倾斜、透视变形**等问题，使得图像更接近“标准”文档的样子，从而为后续的文本识别提供更高质量的输入。\n",
    "\n",
    "### 实战演示：用代码体验文本图像矫正\n",
    "\n",
    "下面我用一段代码来演示一下这个模块的使用方式：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebdbd27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (PP-DocLayout_plus-L), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fff7bbbd4a47cbae9468b867ebcd3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/image.jpg', 'page_index': None, 'boxes': [{'cls_id': 2, 'label': 'text', 'score': 0.7575176358222961, 'coordinate': [np.float32(1285.9551), np.float32(1711.5494), np.float32(1714.0671), np.float32(2082.0159)]}, {'cls_id': 2, 'label': 'text', 'score': 0.6536715626716614, 'coordinate': [np.float32(855.67084), np.float32(1611.6976), np.float32(1208.881), np.float32(2212.0989)]}, {'cls_id': 2, 'label': 'text', 'score': 0.6392190456390381, 'coordinate': [np.float32(1814.1279), np.float32(1684.3706), np.float32(2202.0146), np.float32(2141.768)]}, {'cls_id': 2, 'label': 'text', 'score': 0.5184097290039062, 'coordinate': [np.float32(1303.5271), np.float32(2241.2612), np.float32(2005.0392), np.float32(2344.6514)]}, {'cls_id': 0, 'label': 'paragraph_title', 'score': 0.5072970986366272, 'coordinate': [np.float32(1331.5743), np.float32(1648.6868), np.float32(1722.4619), np.float32(1712.2705)]}]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 不能正确识别的图像\n",
    "\n",
    "from paddleocr import LayoutDetection\n",
    "\n",
    "model = LayoutDetection(model_name=\"PP-DocLayout_plus-L\")\n",
    "output = model.predict(\"./pics/image.jpg\", batch_size=1, layout_nms=True)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./output07/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec875e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (UVDoc), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c39eb90ae46948dc886d0b9054140543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/image.jpg', 'page_index': None, 'doctr_img': '...'}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import TextImageUnwarping\n",
    "model = TextImageUnwarping(model_name=\"UVDoc\")\n",
    "output = model.predict(\"./pics/image.jpg\", batch_size=1)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./pics/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4216de",
   "metadata": {},
   "source": [
    "### 这段代码做了什么？\n",
    "\n",
    "使用 TextImageUnwarping 类加载了名为 UVDoc 的文本图像矫正模型；\n",
    "\n",
    "对本地文件 doc_test.jpg 进行图像矫正推理；\n",
    "\n",
    "输出矫正后的图像结果，并保存为图片和 JSON 文件，便于后续分析和调用。\n",
    "\n",
    "运行后你会看到，原本倾斜或扭曲 的文档图像已经被自动“拉直”，变得更适合 OCR 识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e07a378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (PP-DocLayout_plus-L), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59295aec2e9743e7a6563876a3e896ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/image_res.jpg', 'page_index': None, 'boxes': [{'cls_id': 2, 'label': 'text', 'score': 0.8861143589019775, 'coordinate': [np.float32(996.63605), np.float32(1533.3918), np.float32(1581.1954), np.float32(1925.9213)]}, {'cls_id': 2, 'label': 'text', 'score': 0.7849099636077881, 'coordinate': [np.float32(158.78006), np.float32(1498.5908), np.float32(881.00464), np.float32(2186.8235)]}, {'cls_id': 2, 'label': 'text', 'score': 0.771456778049469, 'coordinate': [np.float32(1715.4049), np.float32(1525.8024), np.float32(2257.6177), np.float32(1989.1323)]}, {'cls_id': 2, 'label': 'text', 'score': 0.6567004919052124, 'coordinate': [np.float32(1019.5312), np.float32(2121.3577), np.float32(1944.7799), np.float32(2233.2126)]}, {'cls_id': 0, 'label': 'paragraph_title', 'score': 0.6213204860687256, 'coordinate': [np.float32(1091.3735), np.float32(1457.0441), np.float32(1592.3569), np.float32(1521.407)]}, {'cls_id': 0, 'label': 'paragraph_title', 'score': 0.5970951914787292, 'coordinate': [np.float32(1771.0332), np.float32(1457.3167), np.float32(2276.109), np.float32(1513.9646)]}, {'cls_id': 1, 'label': 'image', 'score': 0.5716795921325684, 'coordinate': [np.float32(873.7239), np.float32(2074.374), np.float32(967.65393), np.float32(2224.6228)]}, {'cls_id': 0, 'label': 'paragraph_title', 'score': 0.5105922222137451, 'coordinate': [np.float32(444.90115), np.float32(1426.1348), np.float32(784.671), np.float32(1507.5856)]}, {'cls_id': 10, 'label': 'doc_title', 'score': 0.5035927891731262, 'coordinate': [np.float32(492.9438), np.float32(1179.2163), np.float32(2259.3022), np.float32(1424.5831)]}]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 能正确识别的图像\n",
    "\n",
    "from paddleocr import LayoutDetection\n",
    "\n",
    "model = LayoutDetection(model_name=\"PP-DocLayout_plus-L\")\n",
    "output = model.predict(\"./pics/image_res.jpg\", batch_size=1, layout_nms=True)\n",
    "for res in output:\n",
    "    res.print()\n",
    "    res.save_to_img(save_path=\"./output07-2/\")\n",
    "    res.save_to_json(save_path=\"./output07-2/res.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c170643",
   "metadata": {},
   "source": [
    "# 针对表格内容，我们有另一套完整的解决方案！\n",
    "\n",
    "在处理包含表格的文档图像时，仅仅依靠 OCR 是不够的。为了更高效、准确地提取表格信息，PaddleOCR 提供了一套完整的表格识别模块体系。\n",
    "\n",
    "这套方案包括三个核心模块：\n",
    "\n",
    "- 表格分类模块  \n",
    "- 表格单元格检测模块  \n",
    "- 表格结构识别模块  \n",
    "\n",
    "它们各自解决的问题如下表所示：\n",
    "\n",
    "| 模块名称             | 主要功能                                     | 解决问题示例                             |\n",
    "|----------------------|----------------------------------------------|------------------------------------------|\n",
    "| 表格分类模块         | 对表格图像进行分类（如有线表、无线表等）     | 为后续识别流程提供先验信息               |\n",
    "| 表格单元格检测模块   | 定位并标记每个单元格的边界框                 | 精准划分单元格区域，便于内容提取         |\n",
    "| 表格结构识别模块     | 将表格图像转换为可编辑的 HTML 结构           | 实现表格结构还原和语义理解               |\n",
    "\n",
    "接下来我将逐一为你演示这三个模块的功能和使用方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d9519",
   "metadata": {},
   "source": [
    "## 4.1 表格分类模块：为表格识别提供“第一印象”\n",
    "\n",
    "表格分类模块是计算机视觉系统中的关键组成部分，负责对输入的表格图像进行分类。\n",
    "\n",
    "该模块的性能直接影响到整个表格识别过程的准确性和效率。\n",
    "\n",
    "它通常接收表格图像作为输入，然后通过深度学习算法，根据图像的特性和内容，将其分类到预定义的类别中，例如：\n",
    "\n",
    "- 有线表（线条清晰可见）\n",
    "- 无线表（无明显边框）\n",
    "\n",
    "分类结果将作为后续模块的重要参考，帮助系统选择合适的识别策略。\n",
    "\n",
    "示例输出："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06decce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (PP-LCNet_x1_0_table_cls), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca112d707c34192a2528278e88941e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/table_recognition.png', 'page_index': None, 'class_ids': array([0, 1], shape=(2,), dtype=int32), 'scores': array([0.84421, 0.15579], shape=(2,), dtype=float32), 'label_names': ['wired_table', 'wireless_table']}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import TableClassification\n",
    "model = TableClassification(model_name=\"PP-LCNet_x1_0_table_cls\")\n",
    "output = model.predict(\"./pics/table_recognition.png\", batch_size=1)\n",
    "for res in output:\n",
    "    res.print(json_format=False)\n",
    "    res.save_all(\"./output07-3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f71f75",
   "metadata": {},
   "source": [
    "## 4.2 表格单元格检测模块：精准定位每一个单元格\n",
    "\n",
    "表格单元格检测模块是表格识别任务的关键组成部分。\n",
    "\n",
    "它的主要职责是在表格图像中定位和标记每个单元格区域 。\n",
    "\n",
    "模块通常会输出各个单元格区域的边界框（Bounding Boxes），这些边界框将作为输入传递给后续流程进行内容识别和结构重建。\n",
    "\n",
    "输出示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc84c1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (RT-DETR-L_wired_table_cell_det), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3cde757ed0e4b2ba4e26e903b9437d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/table_recognition.png', 'page_index': None, 'boxes': [{'cls_id': 0, 'label': 'cell', 'score': 0.973805844783783, 'coordinate': [np.float32(2.1718848), 0, np.float32(546.6909), np.float32(30.749983)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9714836478233337, 'coordinate': [np.float32(212.63258), np.float32(30.765705), np.float32(403.77368), np.float32(64.7576)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.971441388130188, 'coordinate': [np.float32(212.49472), np.float32(64.74863), np.float32(403.75485), np.float32(95.76425)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9697222113609314, 'coordinate': [np.float32(403.74326), np.float32(30.796143), np.float32(547.1804), np.float32(64.749825)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9692213535308838, 'coordinate': [np.float32(403.74915), np.float32(64.73799), np.float32(547.0551), np.float32(95.78832)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9691973924636841, 'coordinate': [np.float32(109.67606), np.float32(64.78539), np.float32(212.63466), np.float32(95.76532)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9685205221176147, 'coordinate': [np.float32(212.61052), np.float32(95.784546), np.float32(403.7404), np.float32(126.98749)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9679077863693237, 'coordinate': [np.float32(109.73422), np.float32(30.759245), np.float32(212.78757), np.float32(64.776344)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9678134322166443, 'coordinate': [np.float32(2.2161355), np.float32(30.721222), np.float32(109.680664), np.float32(64.74744)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9674668312072754, 'coordinate': [np.float32(2.2394247), np.float32(64.73241), np.float32(109.68649), np.float32(95.716705)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.966941237449646, 'coordinate': [np.float32(2.010712), np.float32(95.72054), np.float32(109.6797), np.float32(126.89888)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9664348363876343, 'coordinate': [np.float32(403.84824), np.float32(95.82774), np.float32(547.1554), np.float32(126.90314)]}, {'cls_id': 0, 'label': 'cell', 'score': 0.9646962881088257, 'coordinate': [np.float32(109.66238), np.float32(95.782585), np.float32(212.61777), np.float32(127.005714)]}]}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import TableCellsDetection\n",
    "model = TableCellsDetection(model_name=\"RT-DETR-L_wired_table_cell_det\")\n",
    "output = model.predict(\"./pics/table_recognition.png\", threshold=0.3, batch_size=1)\n",
    "for res in output:\n",
    "    res.print(json_format=False)\n",
    "    res.save_to_img(\"./output07-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c65ae6",
   "metadata": {},
   "source": [
    "## 4.3 表格结构识别模块：从图像到可编辑表格\n",
    "\n",
    "表格结构识别模块是表格识别系统中的“最终呈现层”。\n",
    "\n",
    "它的目标是将不可编辑的表格图像转换为可编辑的结构化形式 ，如 HTML 表格。\n",
    "\n",
    "通过对表格的行、列和单元格位置进行识别，该模块可以生成标准的 HTML 代码，实现表格的完整结构还原。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f64e1af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mMKL-DNN is not available. Using `paddle` instead.\u001b[0m\n",
      "\u001b[32mUsing official model (SLANet), the model files will be automatically downloaded and saved in /Users/wilson/.paddlex/official_models.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6090a383ebbd41928af9fe307bed65cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m{'res': {'input_path': './pics/table_recognition.png', 'page_index': None, 'bbox': [[42, 2, 390, 2, 388, 27, 40, 26], [11, 35, 89, 35, 87, 63, 11, 63], [113, 34, 192, 34, 186, 64, 109, 64], [219, 33, 399, 33, 393, 62, 212, 62], [413, 33, 544, 33, 544, 64, 407, 64], [12, 67, 98, 68, 96, 93, 12, 93], [115, 66, 205, 66, 200, 91, 111, 91], [234, 65, 390, 65, 385, 92, 227, 92], [414, 66, 537, 67, 537, 95, 409, 95], [7, 97, 106, 97, 104, 128, 7, 128], [113, 96, 206, 95, 201, 127, 109, 127], [236, 96, 386, 96, 381, 128, 230, 128], [413, 96, 534, 95, 533, 127, 408, 127]], 'structure': ['<html>', '<body>', '<table>', '<tr>', '<td', ' colspan=\"4\"', '>', '</td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '<tr>', '<td></td>', '<td></td>', '<td></td>', '<td></td>', '</tr>', '</table>', '</body>', '</html>'], 'structure_score': np.float32(0.99948007)}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import TableStructureRecognition\n",
    "model = TableStructureRecognition(model_name=\"SLANet\")\n",
    "output = model.predict(input=\"./pics/table_recognition.png\", batch_size=1)\n",
    "for res in output:\n",
    "    res.print(json_format=False)\n",
    "    res.save_all(\"./output07-5/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e0dd2",
   "metadata": {},
   "source": [
    "## 5 本讲小结\n",
    "在本讲中，我们深入探讨了 OCR 处理中文档图像常见的“图像切分不合理”问题，并介绍了 PaddleOCR 提供的两个关键预处理模块：\n",
    "\n",
    "- 文本图像矫正模块（Text Image Unwarping） ：用于纠正图像中的文档扭曲、倾斜、透视变形等问题，使图像更接近标准文档形式，从而提升识别准确率。\n",
    "- 版面区域检测模块（Layout Detection） ：对文档图像进行内容解析和区域划分，精准识别出如文字、表格、图像、公式等多种元素，并分类标注其位置，保障信息完整且不冗余。\n",
    "\n",
    "这些模块都可以独立集成到你自己的 OCR 流程中 ，灵活应对各种复杂场景下的图像质量问题。\n",
    "\n",
    "此外，我们也了解到，在面对表格类文档时，PaddleOCR 还提供了一整套完整的识别流程：\n",
    "表格分类模块：识别表格类型\n",
    "表格单元格检测模块：定位每个单元格边界\n",
    "表格结构识别模块：输出 HTML 形式的结构化表格\n",
    "通过这些模块的协同工作，我们可以实现从原始图像到结构化信息的完整转换，显著提升 OCR 系统在复杂文档场景下的鲁棒性和实用性。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
