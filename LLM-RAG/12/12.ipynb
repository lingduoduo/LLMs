{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c2908a",
   "metadata": {},
   "source": [
    "# 12. ç”¨æˆ·æŸ¥è¯¢å¤ªæ¨¡ç³Šï¼Ÿé€šè¿‡æŸ¥è¯¢æ‰©å±•ï¼Œæå‡è¯­ä¹‰åŒ¹é…èƒ½åŠ›\n",
    "\n",
    "## ä¸€ã€ä¸ºä»€ä¹ˆè¦åœ¨ RAG ä¸­è¿›è¡Œ Query Expansionï¼Ÿ\n",
    "\n",
    "åœ¨æ„å»ºåŸºäº **RAGï¼ˆRetrieval-Augmented Generationï¼‰** çš„é—®ç­”ç³»ç»Ÿæ—¶ï¼Œç”¨æˆ·è¾“å…¥å¾€å¾€å­˜åœ¨ä»¥ä¸‹å‡ ä¸ªå¸¸è§é—®é¢˜ï¼š\n",
    "\n",
    "- è¡¨è¾¾æ¨¡ç³Šã€ä¸å®Œæ•´æˆ–å£è¯­åŒ–  \n",
    "- ç¼ºä¹ä¸Šä¸‹æ–‡ä¿¡æ¯  \n",
    "- éš¾ä»¥å‡†ç¡®å‘½ä¸­çŸ¥è¯†åº“ä¸­çš„ç›¸å…³æ–‡æ¡£  \n",
    "\n",
    "å¦‚æœç›´æ¥ä½¿ç”¨ç”¨æˆ·çš„åŸå§‹æŸ¥è¯¢è¿›è¡Œå‘é‡æ£€ç´¢ï¼Œå¯èƒ½ä¼šå¯¼è‡´ä»¥ä¸‹é—®é¢˜ï¼š\n",
    "\n",
    "- å¬å›ç»“æœä¸è¶³  \n",
    "- å‘½ä¸­æ— å…³å†…å®¹  \n",
    "- æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆä¸å¤Ÿå‡†ç¡®æˆ–å…¨é¢  \n",
    "\n",
    "å› æ­¤ï¼Œåœ¨æ‰§è¡Œæ£€ç´¢å‰å¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œ **è¯­ä¹‰çº§æ‰©å±•ä¸æ”¹å†™ï¼ˆQuery Expansion / Rewritingï¼‰**ï¼Œæ˜¯ä¸€ç§æœ‰æ•ˆçš„ä¼˜åŒ–æ‰‹æ®µã€‚\n",
    "\n",
    "### ç¤ºä¾‹ï¼šæ¨¡ç³ŠæŸ¥è¯¢ç¤ºä¾‹\n",
    "\n",
    "é¢å¯¹å¦‚ä¸‹æ¨¡ç³Šçš„ç”¨æˆ·æé—®ï¼š\n",
    "\n",
    "- â€œæˆ‘æƒ³å»å¥½ç©çš„åœ°æ–¹â€  \n",
    "- â€œæœ‰æ²¡æœ‰å¥½åƒçš„â€  \n",
    "- â€œé€‚åˆäº²å­æ¸¸çš„åœ°æ–¹â€  \n",
    "\n",
    "è¿™äº›é—®é¢˜ç¼ºä¹å…·ä½“çš„èƒŒæ™¯ä¿¡æ¯å’Œæ˜ç¡®çš„éœ€æ±‚æè¿°ï¼Œç›´æ¥æ£€ç´¢å¾€å¾€éš¾ä»¥å‘½ä¸­å…³é”®å†…å®¹ã€‚\n",
    "\n",
    "### è§£å†³æ–¹æ¡ˆ\n",
    "\n",
    "ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œå¯ä»¥é‡‡ç”¨ä»¥ä¸‹ä¸¤ç§ç­–ç•¥æ¥å¢å¼ºæ£€ç´¢æ•ˆæœï¼š\n",
    "\n",
    "1. **é—®é¢˜æ”¹å†™ï¼ˆQuery Rewritingï¼‰**  \n",
    "   å°†æ¨¡ç³Šé—®é¢˜è½¬åŒ–ä¸ºæ›´æ¸…æ™°ã€å…·ä½“çš„é—®é¢˜ï¼Œæå‡è¯­ä¹‰è¡¨è¾¾èƒ½åŠ›ã€‚\n",
    "\n",
    "2. **å¤šæ­¥éª¤æ£€ç´¢ï¼ˆMulti-step Queryingï¼‰**  \n",
    "   å°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå¤šä¸ªå­ä»»åŠ¡ï¼Œé€æ­¥æ£€ç´¢åæ•´åˆç­”æ¡ˆï¼Œæé«˜æ£€ç´¢çš„å…¨é¢æ€§å’Œå‡†ç¡®æ€§ã€‚\n",
    "\n",
    "## äºŒ ä¼˜åŒ–æ‰‹æ®µ\n",
    "### 2.1 åœ¨æ£€ç´¢å‰è¿›è¡Œé—®é¢˜æ”¹å†™ï¼ˆQuery Rewritingï¼‰\n",
    "\n",
    "å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b09521",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain faiss-cpu transformers torch sentence-transformers dashscope langchain-community \"unstructured[md]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985ecca",
   "metadata": {},
   "source": [
    "åŠ è½½æ–‡æ¡£å¹¶æ„å»º FAISS å‘é‡åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "775c30af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 15:04:19,837 - INFO - æ­£åœ¨åˆå§‹åŒ–qwen-plusæ¨¡å‹...\n",
      "2025-07-16 15:04:20,005 - INFO - ä»./12/data/åŠ è½½æ–‡æ¡£...\n",
      "2025-07-16 15:04:24,349 - INFO - æˆåŠŸåŠ è½½5ä¸ªæ–‡æ¡£\n",
      "2025-07-16 15:04:24,350 - INFO - æ­£åœ¨è¿›è¡Œæ–‡æ¡£åˆ‡ç‰‡...\n",
      "2025-07-16 15:04:24,350 - INFO - æ–‡æ¡£åˆ‡ç‰‡å®Œæˆï¼Œè·å¾—5ä¸ªæ–‡æœ¬å—\n",
      "2025-07-16 15:04:24,351 - INFO - åŠ è½½text-embedding-v4åµŒå…¥æ¨¡å‹...\n",
      "2025-07-16 15:04:24,352 - INFO - æ„å»ºFAISSå‘é‡åº“...\n",
      "2025-07-16 15:04:24,831 - INFO - Loading faiss.\n",
      "2025-07-16 15:04:24,877 - INFO - Successfully loaded faiss.\n",
      "2025-07-16 15:04:24,882 - INFO - Failed to load GPU Faiss: name 'GpuIndexIVFFlat' is not defined. Will not load constructor refs for GPU indexes. This is only an error if you're trying to use GPU Faiss.\n",
      "2025-07-16 15:04:24,883 - INFO - åˆ›å»ºRAGæŸ¥è¯¢é“¾...\n",
      "2025-07-16 15:04:24,884 - INFO - RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œready for query!\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import DashScopeEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# é…ç½®\n",
    "DOCUMENT_PATH = './12/data/' \n",
    "FILE_PATTERN = '*.md'\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 200\n",
    "# é€šä¹‰Embeddingæ¨¡å‹\n",
    "EMBEDDING_MODEL = 'text-embedding-v4'\n",
    "LLM_MODEL = 'qwen-plus'  # æ”¯æŒqwen-plus/qwen-max/qwen-turbo\n",
    "TOP_K = 5\n",
    "\n",
    "# 1. åˆå§‹åŒ–LLMï¼ˆä½¿ç”¨ChatTongyiï¼‰\n",
    "logging.info(f\"æ­£åœ¨åˆå§‹åŒ–{LLM_MODEL}æ¨¡å‹...\")\n",
    "llm = ChatTongyi(\n",
    "    model_name=LLM_MODEL,\n",
    "    api_key=os.getenv(\"DASHSCOPE_API_KEY\"),  # ä½¿ç”¨DashScope API Key\n",
    "    temperature=0.7,\n",
    "    streaming=True  # å¯ç”¨æµå¼è¾“å‡º\n",
    ")\n",
    "\n",
    "# 2. åŠ è½½æ–‡æ¡£\n",
    "logging.info(f\"ä»{DOCUMENT_PATH}åŠ è½½æ–‡æ¡£...\")\n",
    "loader = DirectoryLoader(DOCUMENT_PATH, glob=FILE_PATTERN)\n",
    "docs = loader.load()\n",
    "logging.info(f\"æˆåŠŸåŠ è½½{len(docs)}ä¸ªæ–‡æ¡£\")\n",
    "\n",
    "# 3. æ–‡æ¡£åˆ‡ç‰‡\n",
    "logging.info(\"æ­£åœ¨è¿›è¡Œæ–‡æ¡£åˆ‡ç‰‡...\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP\n",
    ")\n",
    "texts = text_splitter.split_documents(docs)\n",
    "logging.info(f\"æ–‡æ¡£åˆ‡ç‰‡å®Œæˆï¼Œè·å¾—{len(texts)}ä¸ªæ–‡æœ¬å—\")\n",
    "\n",
    "# 4. åˆå§‹åŒ–Embeddingæ¨¡å‹\n",
    "logging.info(f\"åŠ è½½{EMBEDDING_MODEL}åµŒå…¥æ¨¡å‹...\")\n",
    "embeddings = DashScopeEmbeddings(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        dashscope_api_key=os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "    )\n",
    "\n",
    "# 5. æ„å»ºå‘é‡åº“\n",
    "logging.info(\"æ„å»ºFAISSå‘é‡åº“...\")\n",
    "vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': TOP_K})\n",
    "\n",
    "# 6. åˆ›å»ºRAGæŸ¥è¯¢é“¾\n",
    "logging.info(\"åˆ›å»ºRAGæŸ¥è¯¢é“¾...\")\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "logging.info(\"RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œready for query!\")\n",
    "\n",
    "# æ·»åŠ æŸ¥è¯¢ç¤ºä¾‹\n",
    "def query_rag(question):\n",
    "    logging.info(f\"å¤„ç†æŸ¥è¯¢: {question}\")\n",
    "    result = qa_chain.invoke(question)\n",
    "    return result['result']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b37e9c8",
   "metadata": {},
   "source": [
    "ä¼ ç»Ÿæ£€ç´¢æ–¹å¼ï¼ˆæ— ä¼˜åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "254e8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 02:17:04,179 - INFO - å¤„ç†æŸ¥è¯¢: æˆ‘æƒ³å»å¥½ç©çš„åœ°æ–¹?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: æˆ‘æƒ³å»å¥½ç©çš„åœ°æ–¹?\n",
      "ç­”æ¡ˆ: å¦‚æœä½ å–œæ¬¢å¥½ç©çš„åœ°æ–¹ï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹æ¨èï¼š\n",
      "\n",
      "### ä¸»é¢˜å…¬å›­æ¨è\n",
      "1. **ä¸Šæµ·è¿ªå£«å°¼ä¹å›­ï¼ˆä¸Šæµ·ï¼‰**  \n",
      "   - é€‚åˆäº²å­æ¸¸ã€æƒ…ä¾£ã€å®¶åº­å‡ºæ¸¸ã€‚\n",
      "   - é¡¹ç›®ä¸°å¯Œï¼Œå¦‚â€œç±³å¥‡ç«¥è¯ä¸“åˆ—â€ã€â€œåˆ›æé€Ÿå…‰è½®â€ã€â€œé£è·ƒåœ°å¹³çº¿â€ç­‰ã€‚\n",
      "   - æœ‰å¤œé—´ç¯å…‰ç§€å’Œä¸°å¯Œçš„è¡¨æ¼”ã€‚\n",
      "\n",
      "2. **åŒ—äº¬ç¯çƒå½±åŸï¼ˆåŒ—äº¬ï¼‰**  \n",
      "   - å¤šç§äº’åŠ¨é¡¹ç›®ï¼Œé€‚åˆå…¨å®¶æ¸¸ç©ã€‚\n",
      "   - æœ‰å“ˆåˆ©æ³¢ç‰¹ã€å˜å½¢é‡‘åˆšç­‰çƒ­é—¨IPä¸»é¢˜åŒºã€‚\n",
      "\n",
      "3. **å¹¿å·é•¿éš†æ¬¢ä¹ä¸–ç•Œï¼ˆå¹¿å·ï¼‰**  \n",
      "   - åŠ¨ç‰©å›­+æ¸¸ä¹åœº+æ°´ä¸Šä¹å›­ä¸€ä½“åŒ–ã€‚\n",
      "   - é€‚åˆå¸¦å­©å­çš„å®¶åº­ï¼Œè®¾æ–½å¤šæ ·ã€‚\n",
      "\n",
      "### å…¶ä»–ç©æ³•æ¨è\n",
      "- **äº²å­æ¸¸**ï¼šé™¤äº†ä¸»é¢˜å…¬å›­ï¼Œè¿˜å¯ä»¥å»ä¸Šæµ·çš„æµ·æ´‹æ°´æ—é¦†æˆ–è€…åŒ—äº¬çš„åŠ¨ç‰©å›­ã€‚\n",
      "- **æƒ…ä¾£æ¸¸**ï¼šå¦‚æœå–œæ¬¢æµªæ¼«æ°›å›´ï¼Œå¯ä»¥é€‰æ‹©å¤–æ»©å¤œæ™¯ï¼ˆä¸Šæµ·ï¼‰æˆ–æ–°å¤©åœ°æ™šé¤ï¼ˆä¸Šæµ·ï¼‰ã€‚\n",
      "- **èƒŒåŒ…å®¢**ï¼šå¯ä»¥å°è¯•æ­¦åº·è·¯éª‘è¡Œï¼ˆä¸Šæµ·ï¼‰æˆ–æ¢ç´¢è¡¡å±±è·¯çš„å°ä¼—å’–å•¡é¦†ã€‚\n",
      "\n",
      "### å°è´´å£«\n",
      "- å»ºè®®é”™å³°å‡ºè¡Œï¼Œé¿å…èŠ‚å‡æ—¥äººæµé«˜å³°ã€‚\n",
      "- æå‰æŸ¥çœ‹æ™¯ç‚¹å¼€æ”¾æ—¶é—´å’Œé—¨ç¥¨ä¿¡æ¯ã€‚\n",
      "\n",
      "å¦‚æœä½ å‘Šè¯‰æˆ‘å…·ä½“çš„åŸå¸‚æˆ–å…´è¶£ï¼Œæˆ‘å¯ä»¥æä¾›æ›´è¯¦ç»†çš„æ¨èå“¦ï¼\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•æŸ¥è¯¢\n",
    "if __name__ == \"__main__\":\n",
    "    test_question = \"æˆ‘æƒ³å»å¥½ç©çš„åœ°æ–¹?\"\n",
    "    answer = query_rag(test_question)\n",
    "    print(f\"é—®é¢˜: {test_question}\\nç­”æ¡ˆ: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba39a8d",
   "metadata": {},
   "source": [
    "#### 2.1.1 ä½¿ç”¨ LLM æ”¹å†™é—®é¢˜ï¼ˆå¢å¼ºè¯­ä¹‰è¡¨è¾¾ï¼‰\n",
    "Step 1: æˆ‘ä»¬é¦–å…ˆå®šä¹‰ä¸€ä¸ª Prompt æ¨¡æ¿ï¼Œç”¨äºå¼•å¯¼ LLM å¯¹ç”¨æˆ·é—®é¢˜è¿›è¡Œæ”¹å†™ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a9d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "rewrite_prompt = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "ä½ æ˜¯ä¸€ä¸ªæ—…æ¸¸åŠ©æ‰‹ï¼Œè¯·å°†ä»¥ä¸‹ç”¨æˆ·é—®é¢˜æ”¹å†™ä¸ºæ›´æ¸…æ™°ã€å®Œæ•´çš„å½¢å¼ï¼š\n",
    "\n",
    "åŸå§‹é—®é¢˜ï¼š\n",
    "{{question}}\n",
    "\n",
    "è¯·è¾“å‡ºä¸€ä¸ªæ”¹å†™åçš„é—®é¢˜ï¼Œè¦æ±‚ï¼š\n",
    "- æ›´å…·ä½“\n",
    "- åŒ…å«æ—…è¡Œç±»å‹ï¼ˆäº²å­/æƒ…ä¾£/è‡ªé©¾ç­‰ï¼‰\n",
    "- èƒ½å¸®åŠ©ç³»ç»Ÿå‡†ç¡®æ£€ç´¢ç›¸å…³ä¿¡æ¯\n",
    "\n",
    "è¾“å‡ºæ ¼å¼ï¼š\n",
    "[æ”¹å†™å] - <ä½ çš„å›ç­”>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af638836",
   "metadata": {},
   "source": [
    "Step 2: æ‰§è¡Œæ”¹å†™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abaca18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/bss6m08x2ssb9fhhyqwqrgwm0000gn/T/ipykernel_25067/596718747.py:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  return LLMChain(llm=llm, prompt=rewrite_prompt)\n",
      "2025-07-16 15:09:30,889 - INFO - æ­£åœ¨æ”¹å†™é—®é¢˜: æˆ‘æƒ³å»å¥½ç©çš„åœ°æ–¹?\n",
      "/var/folders/6l/bss6m08x2ssb9fhhyqwqrgwm0000gn/T/ipykernel_25067/596718747.py:11: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rewritten_question = rewrite_chain.run(question).strip()\n",
      "2025-07-16 15:09:30,890 - ERROR - æ”¹å†™é—®é¢˜æ—¶å‡ºé”™: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ”¹å†™åé—®é¢˜: æ”¹å†™é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "# åˆå§‹åŒ–æ”¹å†™é“¾\n",
    "def create_rewrite_chain(llm): \n",
    "    return LLMChain(llm=llm, prompt=rewrite_prompt)\n",
    "\n",
    "# æ‰§è¡Œé—®é¢˜æ”¹å†™\n",
    "def rewrite_question(rewrite_chain, question): \n",
    "    logging.info(f\"æ­£åœ¨æ”¹å†™é—®é¢˜: {question}\")\n",
    "    try:\n",
    "        rewritten_question = rewrite_chain.run(question).strip()\n",
    "        if not rewritten_question:\n",
    "            logging.warning(\"æ”¹å†™åçš„é—®é¢˜ä¸ºç©º\")\n",
    "            return \"æœªè·å¾—æœ‰æ•ˆçš„æ”¹å†™ç»“æœ\"\n",
    "        return rewritten_question\n",
    "    except Exception as e:\n",
    "        logging.error(f\"æ”¹å†™é—®é¢˜æ—¶å‡ºé”™: {str(e)}\")\n",
    "        return \"æ”¹å†™é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯\"\n",
    "\n",
    "\n",
    "\n",
    "rewrite_chain = create_rewrite_chain(llm)\n",
    "test_question = \"æˆ‘æƒ³å»å¥½ç©çš„åœ°æ–¹?\"\n",
    "rewritten = rewrite_question(rewrite_chain, test_question)\n",
    "print(f\"æ”¹å†™åé—®é¢˜: {rewritten}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27c1f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 02:25:24,711 - INFO - å¤„ç†æŸ¥è¯¢: [æ”¹å†™å] - æœ‰æ²¡æœ‰é€‚åˆäº²å­æ¸¸çš„å¥½ç©åœ°æ–¹æ¨èï¼Ÿ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "é—®é¢˜: [æ”¹å†™å] - æœ‰æ²¡æœ‰é€‚åˆäº²å­æ¸¸çš„å¥½ç©åœ°æ–¹æ¨èï¼Ÿ\n",
      "ç­”æ¡ˆ: å½“ç„¶æœ‰ï¼ä»¥ä¸‹æ˜¯å‡ ä¸ªé€‚åˆäº²å­æ¸¸çš„ä¸»é¢˜å…¬å›­æ¨èï¼š\n",
      "\n",
      "1. **ä¸Šæµ·è¿ªå£«å°¼ä¹å›­ï¼ˆä¸Šæµ·ï¼‰**  \n",
      "   - è®¾æ–½å®Œå–„ï¼Œå„¿ç«¥æ¸¸ä¹åŒºä¸°å¯Œã€‚\n",
      "   - æ‹¥æœ‰å¤šä¸ªé€‚åˆå­©å­çš„é¡¹ç›®ï¼Œå¦‚â€œç±³å¥‡ç«¥è¯ä¸“åˆ—â€ã€â€œåˆ›æé€Ÿå…‰è½®â€ç­‰ã€‚\n",
      "   - æä¾›å©´å„¿è½¦ç§Ÿèµã€å“ºä¹³å®¤å’Œäº²å­é¤å…ç­‰æœåŠ¡ã€‚\n",
      "\n",
      "2. **åŒ—äº¬ç¯çƒå½±åŸï¼ˆåŒ—äº¬ï¼‰**  \n",
      "   - å¤šç§äº’åŠ¨é¡¹ç›®ï¼Œé€‚åˆå…¨å®¶ä¸€èµ·æ¸¸ç©ã€‚\n",
      "   - æœ‰ä¸°å¯Œçš„è§’è‰²äº’åŠ¨å’Œä¸»é¢˜å›­åŒºï¼Œè®©å­©å­ä½“éªŒæ²‰æµ¸å¼å¨±ä¹ã€‚\n",
      "\n",
      "3. **å¹¿å·é•¿éš†æ¬¢ä¹ä¸–ç•Œï¼ˆå¹¿å·ï¼‰**  \n",
      "   - é›†åŠ¨ç‰©å›­ã€æ¸¸ä¹åœºã€æ°´ä¸Šä¹å›­äºä¸€ä½“ï¼Œé€‚åˆä¸åŒå¹´é¾„æ®µçš„å­©å­ã€‚\n",
      "   - å®‰å…¨æ€§é«˜ï¼Œå¹¶æä¾›æ¯å©´è®¾æ–½ã€‚\n",
      "\n",
      "è¿™äº›ä¸»é¢˜å…¬å›­çš„å…±åŒä¼˜ç‚¹åŒ…æ‹¬ï¼šæä¾›å©´å„¿è½¦ç§ŸèµæœåŠ¡ã€è®¾æœ‰æ¯å©´å®¤ã€ä»¥åŠå®‰å…¨æ€§è¾ƒé«˜ï¼Œéå¸¸é€‚åˆå¸¦ä½é¾„å„¿ç«¥çš„å®¶åº­å‡ºæ¸¸ã€‚\n",
      "\n",
      "å¦‚æœéœ€è¦æ›´è¯¦ç»†çš„ä»‹ç»æˆ–å…¶ä»–æ¨èï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\n"
     ]
    }
   ],
   "source": [
    "answer = query_rag(rewritten)\n",
    "print(f\"é—®é¢˜: {rewritten}\\nç­”æ¡ˆ: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6979ebd0",
   "metadata": {},
   "source": [
    "æ£€ç´¢ç»“æœæ›´åŠ èšç„¦äºâ€œäº²å­æ¸¸â€ç›¸å…³å†…å®¹ï¼Œæœ‰æ•ˆæå‡äº†å‡†ç¡®æ€§ã€‚\n",
    "\n",
    "### 2.2 å¤šæ­¥éª¤æ£€ç´¢ï¼ˆMulti-step Queryingï¼‰\n",
    "\n",
    "å¯¹äºæ¶‰åŠå¤šä¸ªéœ€æ±‚çš„å¤æ‚é—®é¢˜ï¼Œå•ä¸€æ£€ç´¢å¾€å¾€éš¾ä»¥è¦†ç›–æ‰€æœ‰æ–¹é¢ã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªå­é—®é¢˜ï¼Œåˆ†åˆ«è¿›è¡Œæ£€ç´¢åå†ç»¼åˆç»“æœã€‚\n",
    "\n",
    "ç¤ºä¾‹åœºæ™¯ï¼šæŸ¥æ‰¾é€‚åˆäº²å­æ¸¸çš„æ™¯ç‚¹åŠå‘¨è¾¹ç¾é£Ÿ\n",
    "\n",
    "å¤„ç†æµç¨‹å¦‚ä¸‹ï¼š\n",
    "1. å…ˆæ£€ç´¢â€œäº²å­å‹å¥½å‹æ™¯ç‚¹â€ï¼›\n",
    "2. å†æ ¹æ®è¿™äº›æ™¯ç‚¹ï¼Œæ£€ç´¢â€œé™„è¿‘çš„æ¨èé¤å…â€ï¼›\n",
    "3. æœ€åå°†ä¸¤æ¬¡æ£€ç´¢ç»“æœæ•´åˆï¼Œå½¢æˆå®Œæ•´çš„å›ç­”ã€‚\n",
    "\n",
    "è¿™ç§åˆ†é˜¶æ®µæ£€ç´¢çš„æ–¹å¼èƒ½å¤Ÿæ˜¾è‘—æå‡ç»“æœçš„å‡†ç¡®æ€§å’Œå…¨é¢æ€§ï¼Œå°¤å…¶é€‚ç”¨äºæ¶‰åŠå¤šä¸ªç»´åº¦çš„å¤åˆå‹æŸ¥è¯¢ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e4a1d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6l/bss6m08x2ssb9fhhyqwqrgwm0000gn/T/ipykernel_25067/1306278018.py:53: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  return initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
      "2025-07-16 15:18:01,163 - INFO - å¼€å§‹æ‰§è¡Œå¤šæ­¥æ£€ç´¢: \n",
      "    æˆ‘æƒ³æ‰¾ä¸€ä¸ªé€‚åˆå¸¦å­©å­ç©çš„åœ°æ–¹ï¼Œé™„è¿‘æœ€å¥½æœ‰å¥½åƒçš„é¤å…ã€‚\n",
      "    å…ˆæŸ¥æœ‰å“ªäº›äº²å­å‹å¥½æ™¯ç‚¹ï¼Œå†æ‰¾é™„è¿‘çš„é¤é¥®æ¨èã€‚\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 15:18:02,638 - INFO - æ­£åœ¨æ£€ç´¢äº²å­å‹å¥½å‹æ™¯ç‚¹: äº²å­æ¸¸ç©\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mæˆ‘éœ€è¦å…ˆæŸ¥æ‰¾äº²å­å‹å¥½å‹æ™¯ç‚¹ï¼Œå†æ ¹æ®æ™¯ç‚¹æŸ¥æ‰¾é™„è¿‘çš„æ¨èé¤å…ã€‚\n",
      "Action: SearchChildFriendlyAttractions\n",
      "Action Input: äº²å­æ¸¸ç©\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3må¦‚æœä½ è®¡åˆ’äº²å­æ¸¸ç©ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›é€‚åˆå®¶åº­å¸¦å­©å­çš„ä¸»é¢˜å…¬å›­æ¨èï¼š\n",
      "\n",
      "### 1. ä¸Šæµ·è¿ªå£«å°¼ä¹å›­ï¼ˆä¸Šæµ·ï¼‰\n",
      "- **ç‰¹è‰²**ï¼šä¸­å›½å¤§é™†é¦–åº§è¿ªå£«å°¼ä¸»é¢˜å…¬å›­ï¼Œæ‹¥æœ‰å¤šä¸ªä¸»é¢˜å›­åŒºï¼Œå¦‚â€œç±³å¥‡ç«¥è¯ä¸“åˆ—â€ã€â€œåˆ›æé€Ÿå…‰è½®â€ã€â€œé£è·ƒåœ°å¹³çº¿â€ç­‰ã€‚\n",
      "- **é€‚åˆäººç¾¤**ï¼šäº²å­æ¸¸ã€æƒ…ä¾£ã€å®¶åº­å‡ºæ¸¸ã€‚\n",
      "- **äº²å­å‹å¥½è®¾æ–½**ï¼š\n",
      "  - å©´å„¿è½¦ç§ŸèµæœåŠ¡\n",
      "  - å“ºä¹³å®¤\n",
      "  - å„¿ç«¥æ¸¸ä¹åŒº\n",
      "  - äº²å­é¤å…\n",
      "- **æ¨èç†ç”±**ï¼šé¡¹ç›®ä¸°å¯Œï¼Œæ²‰æµ¸æ„Ÿå¼ºï¼Œæ˜¯äº²å­æ¸¸çš„é¦–é€‰ç›®çš„åœ°ã€‚\n",
      "- **åœ°å€**ï¼šä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒºå·æ²™é•‡\n",
      "\n",
      "### 2. åŒ—äº¬ç¯çƒå½±åŸï¼ˆåŒ—äº¬ï¼‰\n",
      "- **ç‰¹è‰²**ï¼šå¤šç§äº’åŠ¨é¡¹ç›®ï¼Œé€‚åˆå…¨å®¶ä¸€èµ·ä½“éªŒï¼ŒåŒ…æ‹¬å“ˆåˆ©æ³¢ç‰¹ã€å˜å½¢é‡‘åˆšç­‰çƒ­é—¨IPã€‚\n",
      "- **é€‚åˆäººç¾¤**ï¼šå®¶åº­å‡ºæ¸¸ã€‚\n",
      "- **äº²å­å‹å¥½è®¾æ–½**ï¼šå©´å„¿è½¦ç§Ÿèµã€æ¯å©´å®¤ã€‚\n",
      "\n",
      "### 3. å¹¿å·é•¿éš†æ¬¢ä¹ä¸–ç•Œï¼ˆå¹¿å·ï¼‰\n",
      "- **ç‰¹è‰²**ï¼šåŠ¨ç‰©å›­+æ¸¸ä¹åœº+æ°´ä¸Šä¹å›­ä¸€ä½“åŒ–ï¼Œä¸€ç«™å¼æ»¡è¶³äº²å­éœ€æ±‚ã€‚\n",
      "- **é€‚åˆäººç¾¤**ï¼šäº²å­å®¶åº­ã€‚\n",
      "- **äº²å­å‹å¥½è®¾æ–½**ï¼šå©´å„¿è½¦ç§Ÿèµã€æ¯å©´å®¤ã€å®‰å…¨æ€§é«˜çš„å„¿ç«¥åŒºåŸŸã€‚\n",
      "\n",
      "### æ—…è¡Œå»ºè®®\n",
      "- **é”™å³°å‡ºè¡Œ**ï¼šå°½é‡é¿å¼€èŠ‚å‡æ—¥å’Œå‘¨æœ«é«˜å³°ï¼Œå‡å°‘æ’é˜Ÿæ—¶é—´ã€‚\n",
      "- **å…³æ³¨æœ€ä½³æ—…æ¸¸æ—¶é—´**ï¼š\n",
      "  - ä¸Šæµ·ï¼šæ˜¥ç§‹å­£ï¼ˆ3æœˆ-5æœˆã€9æœˆ-11æœˆï¼‰ä¸ºæœ€ä½³å­£èŠ‚ã€‚\n",
      "  - åŒ—äº¬ï¼šæ˜¥ç§‹ä¸¤å­£ï¼ˆ4æœˆ-6æœˆã€9æœˆ-10æœˆï¼‰æœ€åˆé€‚ã€‚\n",
      "  - æ¡‚æ—ï¼š4æœˆ-11æœˆè¾ƒå®œï¼Œä½†éœ€é¿å¼€å¤å­£æš´é›¨é«˜å³°æœŸã€‚\n",
      "\n",
      "å¦‚æœéœ€è¦æ›´å¤šå…·ä½“ä¿¡æ¯ï¼Œæ¯”å¦‚å¦‚ä½•è§„åˆ’è¡Œç¨‹æˆ–å‘¨è¾¹é…å¥—æ™¯ç‚¹ï¼Œä¹Ÿå¯ä»¥å‘Šè¯‰æˆ‘å“¦ï¼\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 15:18:18,596 - INFO - æ­£åœ¨æ£€ç´¢é™„è¿‘çš„æ¨èé¤å…: ä¸Šæµ·è¿ªå£«å°¼ä¹å›­\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mæˆ‘éœ€è¦æ ¹æ®æ¨èçš„äº²å­æ™¯ç‚¹åˆ†åˆ«æŸ¥æ‰¾é™„è¿‘çš„æ¨èé¤å…ã€‚é¦–å…ˆé€‰æ‹©å…¶ä¸­ä¸€ä¸ªæ™¯ç‚¹ï¼Œä¾‹å¦‚â€œä¸Šæµ·è¿ªå£«å°¼ä¹å›­â€ï¼Œç„¶åæ£€ç´¢å…¶å‘¨è¾¹çš„é¤é¥®æ¨èã€‚\n",
      "\n",
      "Action: SearchNearbyRestaurants\n",
      "Action Input: ä¸Šæµ·è¿ªå£«å°¼ä¹å›­\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mä¸Šæµ·è¿ªå£«å°¼ä¹å›­æ˜¯ä¸­å›½å¤§é™†é¦–åº§è¿ªå£«å°¼ä¸»é¢˜å…¬å›­ï¼Œä½äºä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒºå·æ²™é•‡ã€‚å®ƒæ˜¯ä¸€ä¸ªé€‚åˆäº²å­æ¸¸ã€æƒ…ä¾£å’Œå®¶åº­å‡ºæ¸¸çš„ç†æƒ³ç›®çš„åœ°ã€‚\n",
      "\n",
      "### ä¸»é¢˜å›­åŒºä¸é¡¹ç›®\n",
      "ä¸Šæµ·è¿ªå£«å°¼ä¹å›­æ‹¥æœ‰å¤šä¸ªç²¾å½©çš„ä¸»é¢˜å›­åŒºï¼Œå…¶ä¸­åŒ…æ‹¬ï¼š\n",
      "- **ç±³å¥‡ç«¥è¯ä¸“åˆ—**ï¼šå……æ»¡ç«¥è¯è‰²å½©çš„å·¡æ¸¸ä½“éªŒã€‚\n",
      "- **åˆ›æé€Ÿå…‰è½®**ï¼šä»¥ã€Šåˆ›ã€‹ç”µå½±ä¸ºèƒŒæ™¯çš„é«˜é€Ÿåˆºæ¿€è¿‡å±±è½¦ã€‚\n",
      "- **é£è·ƒåœ°å¹³çº¿**ï¼šèº«ä¸´å…¶å¢ƒçš„é£è¡Œä½“éªŒé¡¹ç›®ï¼Œå¸¦ä½ ç¯æ¸¸ä¸–ç•Œã€‚\n",
      "\n",
      "æ­¤å¤–ï¼Œå›­å†…è¿˜æœ‰ä¸°å¯Œçš„è¡¨æ¼”æ´»åŠ¨å’Œä»¤äººå¹ä¸ºè§‚æ­¢çš„å¤œé—´ç¯å…‰ç§€ã€‚\n",
      "\n",
      "### äº²å­å‹å¥½è®¾æ–½\n",
      "å¯¹äºå¸¦å­©å­çš„å®¶åº­æ¥è¯´ï¼Œä¹å›­æä¾›äº†è®¸å¤šä¾¿åˆ©è®¾æ–½ï¼ŒåŒ…æ‹¬ï¼š\n",
      "- å©´å„¿è½¦ç§ŸèµæœåŠ¡\n",
      "- å“ºä¹³å®¤\n",
      "- å„¿ç«¥æ¸¸ä¹åŒº\n",
      "- äº²å­é¤å…\n",
      "\n",
      "### æ¨èç†ç”±\n",
      "ä¸Šæµ·è¿ªå£«å°¼ä¹å›­æ˜¯äº²å­æ¸¸çš„é¦–é€‰åœ°ï¼Œä¸ä»…é¡¹ç›®ä¸°å¯Œï¼Œè€Œä¸”æ²‰æµ¸æ„Ÿå¼ºï¼Œéå¸¸é€‚åˆå®¶åº­æ¸¸ç©ã€‚\n",
      "\n",
      "### æ—…è¡Œå»ºè®®\n",
      "- **é”™å³°å‡ºè¡Œ**ï¼šå»ºè®®é¿å¼€èŠ‚å‡æ—¥æˆ–å‘¨æœ«é«˜å³°æ—¶æ®µï¼Œä»¥å‡å°‘æ’é˜Ÿæ—¶é—´ã€‚\n",
      "- **æœ€ä½³å­£èŠ‚**ï¼šæ˜¥ç§‹å­£ï¼ˆ3æœˆ-5æœˆã€9æœˆ-11æœˆï¼‰æ°”å€™å®œäººï¼Œæ˜¯æ¸¸è§ˆçš„æœ€ä½³æ—¶é—´ã€‚\n",
      "\n",
      "å¦‚æœæ‚¨éœ€è¦æ›´å¤šå…³äºäº¤é€šã€é—¨ç¥¨é¢„è®¢æˆ–å…¶ä»–ç»†èŠ‚çš„ä¿¡æ¯ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mæ ¹æ®æˆ‘çš„æœç´¢ï¼Œä¸Šæµ·è¿ªå£«å°¼ä¹å›­æ˜¯ä¸€ä¸ªéå¸¸é€‚åˆäº²å­æ¸¸ç©çš„åœ°æ–¹ï¼ŒåŒæ—¶ä¹å›­å†…å’Œå‘¨è¾¹ä¹Ÿæœ‰è®¸å¤šä¼˜è´¨çš„äº²å­é¤å…ã€‚ä»¥ä¸‹æ˜¯æˆ‘å¯¹é—®é¢˜çš„æ€»ç»“å›ç­”ï¼š\n",
      "\n",
      "Final Answer: æ¨èæ‚¨å‰å¾€ä¸Šæµ·è¿ªå£«å°¼ä¹å›­è¿›è¡Œäº²å­æ¸¸ç©ï¼Œè¿™æ˜¯ä¸€ä¸ªæ²‰æµ¸æ„Ÿå¼ºã€é¡¹ç›®ä¸°å¯Œçš„ä¸»é¢˜å…¬å›­ï¼Œæ‹¥æœ‰å©´å„¿è½¦ç§Ÿèµã€å“ºä¹³å®¤ã€å„¿ç«¥æ¸¸ä¹åŒºç­‰äº²å­å‹å¥½è®¾æ–½ã€‚å›­å†…è¿˜æœ‰å¤šç§äº²å­é¤å…å¯ä¾›é€‰æ‹©ï¼Œä¾‹å¦‚â€œçš‡å®¶å®´ä¼šå…â€ã€â€œå¸•å¸•é‡Œè¯ºæŠ«è¨â€ç­‰ï¼Œæä¾›é€‚åˆå­©å­çš„é¤é£Ÿã€‚æœ€ä½³æ¸¸è§ˆæ—¶é—´ä¸ºæ˜¥ç§‹å­£ï¼ˆ3æœˆ-5æœˆã€9æœˆ-11æœˆï¼‰ï¼Œå»ºè®®é¿å¼€èŠ‚å‡æ—¥é«˜å³°ä»¥å‡å°‘æ’é˜Ÿæ—¶é—´ã€‚\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ğŸ” å¤šæ­¥æ£€ç´¢ç»“æœ:\n",
      "æ¨èæ‚¨å‰å¾€ä¸Šæµ·è¿ªå£«å°¼ä¹å›­è¿›è¡Œäº²å­æ¸¸ç©ï¼Œè¿™æ˜¯ä¸€ä¸ªæ²‰æµ¸æ„Ÿå¼ºã€é¡¹ç›®ä¸°å¯Œçš„ä¸»é¢˜å…¬å›­ï¼Œæ‹¥æœ‰å©´å„¿è½¦ç§Ÿèµã€å“ºä¹³å®¤ã€å„¿ç«¥æ¸¸ä¹åŒºç­‰äº²å­å‹å¥½è®¾æ–½ã€‚å›­å†…è¿˜æœ‰å¤šç§äº²å­é¤å…å¯ä¾›é€‰æ‹©ï¼Œä¾‹å¦‚â€œçš‡å®¶å®´ä¼šå…â€ã€â€œå¸•å¸•é‡Œè¯ºæŠ«è¨â€ç­‰ï¼Œæä¾›é€‚åˆå­©å­çš„é¤é£Ÿã€‚æœ€ä½³æ¸¸è§ˆæ—¶é—´ä¸ºæ˜¥ç§‹å­£ï¼ˆ3æœˆ-5æœˆã€9æœˆ-11æœˆï¼‰ï¼Œå»ºè®®é¿å¼€èŠ‚å‡æ—¥é«˜å³°ä»¥å‡å°‘æ’é˜Ÿæ—¶é—´ã€‚\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents.types import AgentType\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "def setup_logging(): \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "setup_logging()\n",
    "\n",
    "# å®šä¹‰å·¥å…·å‡½æ•°\n",
    "def search_child_friendly_attractions(query): \n",
    "    try:\n",
    "        logging.info(f\"æ­£åœ¨æ£€ç´¢äº²å­å‹å¥½å‹æ™¯ç‚¹: {query}\")\n",
    "        result = qa_chain.run(query)\n",
    "        if not result.strip(): \n",
    "            logging.warning(\"æœªæ£€ç´¢åˆ°äº²å­å‹å¥½å‹æ™¯ç‚¹çš„ç»“æœ\")\n",
    "            return \"æœªæ‰¾åˆ°ç›¸å…³äº²å­å‹å¥½å‹æ™¯ç‚¹\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"æ£€ç´¢äº²å­å‹å¥½å‹æ™¯ç‚¹æ—¶å‡ºé”™: {str(e)}\")\n",
    "        return \"æ£€ç´¢äº²å­å‹å¥½å‹æ™¯ç‚¹æ—¶å‘ç”Ÿé”™è¯¯\"\n",
    "\n",
    "def search_nearby_restaurants(query): \n",
    "    try:\n",
    "        logging.info(f\"æ­£åœ¨æ£€ç´¢é™„è¿‘çš„æ¨èé¤å…: {query}\")\n",
    "        result = qa_chain.run(query)\n",
    "        if not result.strip(): \n",
    "            logging.warning(\"æœªæ£€ç´¢åˆ°é™„è¿‘é¤å…çš„ç»“æœ\")\n",
    "            return \"æœªæ‰¾åˆ°é™„è¿‘çš„æ¨èé¤å…\"\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logging.error(f\"æ£€ç´¢é™„è¿‘é¤å…æ—¶å‡ºé”™: {str(e)}\")\n",
    "        return \"æ£€ç´¢é™„è¿‘é¤å…æ—¶å‘ç”Ÿé”™è¯¯\"\n",
    "\n",
    "# åˆå§‹åŒ–å·¥å…·\n",
    "def initialize_tools(): \n",
    "    return [\n",
    "        Tool(\n",
    "            name=\"SearchChildFriendlyAttractions\",\n",
    "            func=search_child_friendly_attractions,\n",
    "            description=\"ç”¨äºæ£€ç´¢äº²å­å‹å¥½å‹æ™¯ç‚¹ï¼Œè¾“å…¥åº”è¯¥æ˜¯ä¸äº²å­æ¸¸ç©ç›¸å…³çš„é—®é¢˜\"\n",
    "        ),\n",
    "        Tool(\n",
    "            name=\"SearchNearbyRestaurants\",\n",
    "            func=search_nearby_restaurants,\n",
    "            description=\"ç”¨äºæ ¹æ®æ™¯ç‚¹æ£€ç´¢é™„è¿‘çš„æ¨èé¤å…ï¼Œè¾“å…¥åº”è¯¥åŒ…å«æ™¯ç‚¹åç§°\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# åˆå§‹åŒ–ä»£ç†\n",
    "def initialize_search_agent(llm): \n",
    "    tools = initialize_tools()\n",
    "    return initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "# æ‰§è¡Œå¤šæ­¥æ£€ç´¢\n",
    "def run_multi_step_search(agent, query): \n",
    "    try:\n",
    "        logging.info(f\"å¼€å§‹æ‰§è¡Œå¤šæ­¥æ£€ç´¢: {query}\")\n",
    "        response = agent.invoke(query)\n",
    "        formatted_response = f\"ğŸ” å¤šæ­¥æ£€ç´¢ç»“æœ:\\n{response['output']}\"\n",
    "        print(formatted_response)\n",
    "        return formatted_response\n",
    "    except Exception as e:\n",
    "        logging.error(f\"æ‰§è¡Œå¤šæ­¥æ£€ç´¢æ—¶å‡ºé”™: {str(e)}\")\n",
    "        print(\"æ‰§è¡Œå¤šæ­¥æ£€ç´¢æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—\")\n",
    "        return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        if llm is None:\n",
    "            logging.info(\"llm å˜é‡æœªå®šä¹‰ï¼Œæ­£åœ¨ä½¿ç”¨é»˜è®¤ ChatOpenAI è¿›è¡Œåˆå§‹åŒ–ã€‚\")\n",
    "            llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "        if qa_chain is None:\n",
    "            logging.info(\"qa_chain å˜é‡æœªå®šä¹‰ï¼Œæ­£åœ¨ä½¿ç”¨é»˜è®¤ LLMChain è¿›è¡Œåˆå§‹åŒ–ã€‚\")\n",
    "            prompt_template = \"è¯·æ ¹æ®ä»¥ä¸‹é—®é¢˜ç»™å‡ºç›¸å…³ä¿¡æ¯ï¼š{question}\\n\" \\\n",
    "                            \"å¦‚æœæ‰¾ä¸åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜ 'æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯'ã€‚\"\n",
    "            qa_chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(prompt_template))\n",
    "\n",
    "    except NameError:\n",
    "        logging.error(\"llm æˆ– qa_chain å˜é‡æœªå®šä¹‰ï¼Œè¯·ç¡®ä¿åœ¨ä½¿ç”¨å‰æ­£ç¡®åˆå§‹åŒ–\")\n",
    "        raise\n",
    "\n",
    "    agent = initialize_search_agent(llm)\n",
    "    multi_step_query = \"\"\"\n",
    "    æˆ‘æƒ³æ‰¾ä¸€ä¸ªé€‚åˆå¸¦å­©å­ç©çš„åœ°æ–¹ï¼Œé™„è¿‘æœ€å¥½æœ‰å¥½åƒçš„é¤å…ã€‚\n",
    "    å…ˆæŸ¥æœ‰å“ªäº›äº²å­å‹å¥½æ™¯ç‚¹ï¼Œå†æ‰¾é™„è¿‘çš„é¤é¥®æ¨èã€‚\n",
    "    \"\"\"\n",
    "    run_multi_step_search(agent, multi_step_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41efa84d",
   "metadata": {},
   "source": [
    "ä¼˜åŠ¿ï¼š åˆ†é˜¶æ®µæ£€ç´¢ï¼Œæé«˜å‡†ç¡®æ€§å’Œå…¨é¢æ€§ã€‚\n",
    "\n",
    "## 2.3 æ•ˆæœå¯¹æ¯”ä¸è¯„ä¼°\n",
    "\n",
    "ä¸ºäº†éªŒè¯ä¼˜åŒ–ç­–ç•¥çš„æœ‰æ•ˆæ€§ï¼Œå»ºè®®æ„å»ºä¸€ä¸ªå°è§„æ¨¡çš„ Ground Truth æ•°æ®é›† ï¼Œå¹¶è®¾è®¡ç®€å•çš„è¯„ä¼°æŒ‡æ ‡è¿›è¡Œå¯¹æ¯”åˆ†æã€‚\n",
    "\n",
    "è¯„ä¼°æ–¹æ³•ç¤ºä¾‹ï¼š\n",
    "- æ„å»ºåŒ…å«åŸå§‹é—®é¢˜ã€æ”¹å†™åé—®é¢˜ã€æœŸæœ›ç­”æ¡ˆçš„æ•°æ®é›†ï¼›\n",
    "- åˆ¤æ–­æœ€ç»ˆç”Ÿæˆçš„å›ç­”æ˜¯å¦åŒ…å«æ­£ç¡®ç­”æ¡ˆï¼›\n",
    "- ç»Ÿè®¡å‡†ç¡®ç‡æˆ–å¬å›ç‡ç­‰æŒ‡æ ‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e599072d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 15:21:51,627 - INFO - æˆåŠŸæ·»åŠ æ–°çš„è¯„ä¼°ç¤ºä¾‹\n",
      "2025-07-16 15:21:51,628 - INFO - åŸå§‹é—®é¢˜: æˆ‘æƒ³å¸¦å­©å­ç©\n",
      "æ”¹å†™é—®é¢˜: æ¨èé€‚åˆäº²å­æ¸¸ç©çš„ç›®çš„åœ°\n",
      "æ­£ç¡®ç­”æ¡ˆåŒ…å«: âœ…\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¯„ä¼°æŠ¥å‘Š:\n",
      "- æ€»æ ·æœ¬æ•°: 1\n",
      "- æ­£ç¡®æ ·æœ¬æ•°: 1\n",
      "- å‡†ç¡®ç‡: 100.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import List, Dict, Tuple\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# é…ç½®æ—¥å¿—\n",
    "def setup_logging(): \n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "setup_logging()\n",
    "\n",
    "class GroundTruthDataset:\n",
    "    \"\"\"ç®¡ç†åŒ…å«åŸå§‹é—®é¢˜ã€æ”¹å†™åé—®é¢˜å’ŒæœŸæœ›ç­”æ¡ˆçš„æ•°æ®é›†\"\"\"\n",
    "    def __init__(self):\n",
    "        self.data: List[Dict[str, str]] = []\n",
    "\n",
    "    def add_example(self, original_q: str, rewritten_q: str, ground_truth: str):\n",
    "        \"\"\"æ·»åŠ æ•°æ®ç¤ºä¾‹\"\"\"\n",
    "        self.data.append({\n",
    "            'original_q': original_q,\n",
    "            'rewritten_q': rewritten_q,\n",
    "            'ground_truth': ground_truth\n",
    "        })\n",
    "        logging.info(\"æˆåŠŸæ·»åŠ æ–°çš„è¯„ä¼°ç¤ºä¾‹\")\n",
    "\n",
    "    def get_all_examples(self) -> List[Dict[str, str]]:\n",
    "        \"\"\"è·å–æ‰€æœ‰æ•°æ®ç¤ºä¾‹\"\"\"\n",
    "        return self.data\n",
    "\n",
    "class Evaluator:\n",
    "    \"\"\"è¯„ä¼°æ¨¡å‹å›ç­”çš„æ€§èƒ½\"\"\"\n",
    "    def __init__(self, similarity_threshold: float = 0.8):\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "\n",
    "    def _is_answer_correct(self, answer: str, ground_truth: str) -> bool:\n",
    "        \"\"\"ä½¿ç”¨ç›¸ä¼¼åº¦åˆ¤æ–­ç­”æ¡ˆæ˜¯å¦æ­£ç¡®\"\"\"\n",
    "        similarity = SequenceMatcher(None, answer.lower(), ground_truth.lower()).ratio()\n",
    "        return similarity >= self.similarity_threshold\n",
    "\n",
    "    def evaluate_single(self, original_q: str, rewritten_q: str, answer: str, ground_truth: str) -> Tuple[int, Dict[str, str]]:\n",
    "        \"\"\"è¯„ä¼°å•ä¸ªç¤ºä¾‹\"\"\"\n",
    "        score = 1 if self._is_answer_correct(answer, ground_truth) else 0\n",
    "        result = {\n",
    "            'original_q': original_q,\n",
    "            'rewritten_q': rewritten_q,\n",
    "            'answer': answer,\n",
    "            'ground_truth': ground_truth,\n",
    "            'is_correct': score == 1\n",
    "        }\n",
    "        logging.info(f\"åŸå§‹é—®é¢˜: {original_q}\\næ”¹å†™é—®é¢˜: {rewritten_q}\\næ­£ç¡®ç­”æ¡ˆåŒ…å«: {'âœ…' if score else 'âŒ'}\")\n",
    "        return score, result\n",
    "\n",
    "    def evaluate_dataset(self, dataset: GroundTruthDataset, answer_generator) -> Dict[str, float]:\n",
    "        \"\"\"è¯„ä¼°æ•´ä¸ªæ•°æ®é›†\"\"\"\n",
    "        total = len(dataset.get_all_examples())\n",
    "        correct = 0\n",
    "        results = []\n",
    "\n",
    "        for example in dataset.get_all_examples():\n",
    "            try:\n",
    "                answer = answer_generator(example['rewritten_q'])\n",
    "                score, result = self.evaluate_single(\n",
    "                    example['original_q'],\n",
    "                    example['rewritten_q'],\n",
    "                    answer,\n",
    "                    example['ground_truth']\n",
    "                )\n",
    "                correct += score\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"è¯„ä¼°ç¤ºä¾‹æ—¶å‡ºé”™: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        accuracy = correct / total if total > 0 else 0\n",
    "        # å¯ä»¥æ‰©å±•è®¡ç®—å¬å›ç‡ã€ç²¾ç¡®ç‡ã€F1å€¼ç­‰æŒ‡æ ‡\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'correct_count': correct,\n",
    "            'total_count': total,\n",
    "            'results': results\n",
    "        }\n",
    "\n",
    "    def generate_report(self, metrics: Dict[str, float]) -> str:\n",
    "        \"\"\"ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š\"\"\"\n",
    "        report = f\"è¯„ä¼°æŠ¥å‘Š:\\n\"\n",
    "        report += f\"- æ€»æ ·æœ¬æ•°: {metrics['total_count']}\\n\"\n",
    "        report += f\"- æ­£ç¡®æ ·æœ¬æ•°: {metrics['correct_count']}\\n\"\n",
    "        report += f\"- å‡†ç¡®ç‡: {metrics['accuracy']:.2%}\\n\"\n",
    "        return report\n",
    "\n",
    "# ç¤ºä¾‹ä½¿ç”¨\n",
    "if __name__ == \"__main__\":\n",
    "    # åˆå§‹åŒ–æ•°æ®é›†\n",
    "    dataset = GroundTruthDataset()\n",
    "    dataset.add_example(\n",
    "        original_q=\"æˆ‘æƒ³å¸¦å­©å­ç©\",\n",
    "        rewritten_q=\"æ¨èé€‚åˆäº²å­æ¸¸ç©çš„ç›®çš„åœ°\",\n",
    "        ground_truth=\"æ¨èäº†ä¸Šæµ·è¿ªå£«å°¼ä¹å›­å’ŒåŒ—äº¬ç¯çƒå½±åŸä¸¤ä¸ªäº²å­æ¸¸ç›®çš„åœ°\"\n",
    "    )\n",
    "\n",
    "    # æ¨¡æ‹Ÿå›ç­”ç”Ÿæˆå‡½æ•°ï¼ˆå®é™…ä½¿ç”¨æ—¶æ›¿æ¢ä¸ºçœŸå®çš„æ¨¡å‹è°ƒç”¨ï¼‰\n",
    "    def mock_answer_generator(query: str) -> str:\n",
    "        if \"äº²å­æ¸¸ç©\" in query:\n",
    "            return \"æ¨èäº†ä¸Šæµ·è¿ªå£«å°¼ä¹å›­å’ŒåŒ—äº¬ç¯çƒå½±åŸä¸¤ä¸ªäº²å­æ¸¸ç›®çš„åœ°\"\n",
    "        return \"æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯\"\n",
    "\n",
    "    # åˆå§‹åŒ–è¯„ä¼°å™¨\n",
    "    evaluator = Evaluator(similarity_threshold=0.8)\n",
    "\n",
    "    # æ‰§è¡Œè¯„ä¼°\n",
    "    metrics = evaluator.evaluate_dataset(dataset, mock_answer_generator)\n",
    "\n",
    "    # ç”Ÿæˆå¹¶æ‰“å°è¯„ä¼°æŠ¥å‘Š\n",
    "    report = evaluator.generate_report(metrics)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0611f341",
   "metadata": {},
   "source": [
    "é€šè¿‡æ­¤ç±»è¯„ä¼°ï¼Œå¯ä»¥é‡åŒ–ä¸åŒç­–ç•¥çš„æ•ˆæœå·®å¼‚ï¼Œä¸ºåç»­ä¼˜åŒ–æä¾›æ•°æ®æ”¯æŒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f418d",
   "metadata": {},
   "source": [
    "### æ€»ç»“\n",
    "\n",
    "| ä¼˜åŒ–ç‚¹ | æ•ˆæœ |\n",
    "| --- | --- |\n",
    "| é—®é¢˜æ”¹å†™ | æé«˜æ£€ç´¢å‡†ç¡®æ€§ï¼Œé¿å…é—æ¼å…³é”®ä¿¡æ¯ |\n",
    "| å¤šæ­¥éª¤æ£€ç´¢ | æå‡å¤æ‚é—®é¢˜çš„å›ç­”å®Œæ•´æ€§ |\n",
    "| ä¸­æ–‡ Embedding | æå‡å‘é‡å¬å›è´¨é‡ |\n",
    "| æœ¬åœ° LLM | éšç§å®‰å…¨ï¼Œå¯æ§æ€§å¼º |\n",
    "\n",
    "\n",
    "### ä¸‰ã€æ›´å¤šä¼˜åŒ–å»ºè®®\n",
    "\n",
    "| ä¼˜åŒ–æ–¹æ³• | æ”¶ç›Šç‚¹ |\n",
    "| --- | --- |\n",
    "| å¤šå˜ä½“å¬å› + èšåˆ | å°†å¤šä¸ªæ”¹å†™åçš„æŸ¥è¯¢åŒæ—¶æäº¤ç»™å‘é‡åº“ï¼Œèšåˆç»“æœ |\n",
    "| HyDE ç­–ç•¥ | åˆ©ç”¨å‡è®¾æ–‡æ¡£ï¼ˆHypothetical Documentï¼‰è¾…åŠ©æ£€ç´¢ |\n",
    "| å¤šè·¯å¬å› + Reranking | ä½¿ç”¨ rerank æ¨¡å—å¯¹æ£€ç´¢ç»“æœæ‰“åˆ†æ’åºï¼Œæå‡ç²¾åº¦ |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
