{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6abc406d",
   "metadata": {},
   "source": [
    "# 模型忽略关键实体怎么办？注意力权重分配机制引导生成聚焦重点\n",
    "\n",
    "## 场景痛点\n",
    "\n",
    "大语言模型虽然强大，但在特定任务中仍可能出现“走神”现象。\n",
    "\n",
    "例如，在生成摘要时遗漏核心人物名字，在问答系统中无法准确抽取关键日期，或在对话中忽略用户强调的重点。这些情况导致生成内容偏离主题，缺乏关键信息，甚至误导用户。\n",
    "\n",
    "## 根本原因\n",
    "\n",
    "模型在处理文本时，注意力机制未能对关键实体给予足够关注。Transformer 架构通过注意力权重对输入 token 进行加权聚合，从而决定输出内容。如果某些重要实体的注意力权重偏低，它们就很难在最终输出中体现出来。\n",
    "\n",
    "\n",
    "### 方案一： 提示词\n",
    "\n",
    "通过精心设计的 prompt，可以间接引导模型关注特定内容。例如，明确要求模型在回答中使用某些关键词，或以特定结构组织内容。这种方式简单有效，适用于大多数模型\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "请用自然流畅的语言，深入探讨一下人工智能和大模型的未来发展趋势，并结合医疗、自动驾驶、智能客服等具体行业，分析它们的潜在应用和挑战。\n",
    "请在你的回答中，尽可能自然地穿插以下词汇：大模型、人工智能、医疗、自动驾驶、智能客服。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83796bb",
   "metadata": {},
   "source": [
    "### 方案二： 自然语言处理\n",
    "[命名实体识别](https://www.modelscope.cn/models/iic/nlp_seqgpt-560m)\n",
    "\n",
    "借助命名实体识别技术，从输入中提取关键实体，并将其插入 prompt 或用于干预模型生成逻辑。该方法自动化程度高，能动态识别关键信息，但依赖外部模块，推理链更复杂。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82362b",
   "metadata": {},
   "source": [
    "### 方案三：修改 Attention 层，最终生成词汇的概率分布（logits）\n",
    "\n",
    "更直接、有效的方式是干预模型输出层的 logits。logits 是模型对词汇表中每个词的“打分”，在它进入 softmax 之前修改，可以精确提升或降低特定词汇的生成概率。该方法不依赖 prompt，也不需要重新训练模型，适用于推理阶段实时干预。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc14d3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linghuang/miniconda3/envs/llm_clean/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Loading model: Qwen/Qwen2.5-0.5B-Instruct on cpu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "Focused token IDs: [396, 471, 2473, 2717, 4119, 4128, 6002, 9842, 10506, 11229, 12120, 16488, 16767, 20509, 29846]\n",
      "\n",
      "==================== Baseline Generation ====================\n",
      "As an AI language model, I am constantly evolving to understand the complex dynamics of today's world. Here is my perspective on the potential future developments in artificial Intelligence and Large Language Models (LLMs) across various industries:\n",
      "\n",
      "1. Healthcare: The application of LLMs in healthcare can revolutionize the way doctors diagnose and treat diseases. By analyzing vast amounts of medical data, LLLs can provide insights into patient health patterns and predict potential health risks before they occur. This could lead to more personalized medicine, with treatments tailored to individual patients' genetic profiles and medical history. However, there are also ethical concerns about the use of AI in medical diagnostics, particularly when it comes to privacy and consent.\n",
      "\n",
      "2. Autonomous Driving: LLSMs have the ability to process vast quantities of data quickly and accurately, which makes them ideal for autonomous vehicle systems. These systems can learn from real-world data to improve their performance over time, reducing the risk of accidents and improving overall safety. The potential for LLA applications in this area is significant, especially in urban areas where traffic congestion and other factors can limit autonomous car adoption.\n",
      "\n",
      "3. Intelligent Customer Service: AI-powered chatbots can be used to handle customer inquiries and complaints more efficiently. LLLLs, like virtual assistants, can also engage with customers directly, providing personalized assistance and recommendations. While these applications have numerous benefits, they also raise questions about data privacy, security, transparency, accountability, fairness, bias, ethics, liability, trust, innovation, human interaction, customer engagement, business strategy, user experience, emotional intelligence, empathy, etc.\n",
      "\n",
      "In conclusion, while there is immense potential in the development of advanced AI technologies for healthcare and autonomous vehicles, we must also consider the ethical, social, legal, economic, regulatory, technological, cultural, environmental, safety, quality, privacy issues, data protection, cybersecurity, diversity, equity, inclusion, accessibility, impact, risk, responsibility, value, creativity, sustainability, growth, adaptation, adaptability, scalability, resilience, stability, learning, evolution, convergence, symbiosis, collaboration, cooperation, competition, conflict, balance, integration, unity, harmony, cohesion, fusion, transformation, disruption, reconfiguration, restructuring, renewal, rejuvenation, resurrection, revival, regeneration, revitalization, recovery, reconstruction, rehabilitation, resuscitation, rescue, restoration, restorative, repair, recapture, recreation, recuperation. All these aspects need to be addressed carefully to ensure that AI-driven technologies are developed and deployed responsibly and ethically. In doing so, it\n",
      "\n",
      "[Keyword Stats] count=7, present=['large language models', 'artificial intelligence', 'healthcare', 'autonomous driving', 'intelligent customer service']\n",
      "\n",
      "==================== Keyword-Biased Generation ====================\n",
      "As AI technology continues to advance at an unprecedented pace, it's clear that its impact on various industries will expand rapidly in the coming years. In healthcare sectors, for example, AI is already being used to diagnose diseases, predict patient outcomes, assist in drug discovery, optimize treatment plans, reduce medical errors, improve patient care coordination, enhance patient compliance with medical treatments, etc. However, there are also significant challenges to overcome, including ethical concerns around AI bias, privacy issues, data security risks, legal compliance, regulatory uncertainties, job displacement due to automation, cybersecurity threats, human oversight, cultural differences in AI development, lack of adequate training and support for AI professionals, shortage of skilled professionals in certain AI domains, inadequate data quality and quantity, insufficient investment in research and development for advanced AI technologies, reliance on outdated models or tools, technological limitations, resource constraints, environmental impacts, climate change, digital divide, gender bias in decision-making, income inequality, aging population, high mortality rates, rising healthcare costs, increasing healthcare spending, population aging, social unrest, economic instability, terrorism, cyber attacks, terrorist threats to critical infrastructure, war, political instability and conflicts, religious and cultural conflicts in some regions, language barriers, linguistic and language diversity, regional disparities, geographic isolation, socioeconomic disparity, underdevelopment, educational attainment, age structure, living standards, urban-rural disparity in healthcare access, health equity, unequal distribution of resources, healthcare disparities between different regions and countries, disparities in access to healthcare among different demographic groups, service quality, customer satisfaction, product/service quality of healthcare providers, public service delivery models, quality control measures, risk management, safety, reliability, usability, efficiency, cost-effectiveness, sustainability, effectiveness, innovation, disruption, competition, growth, decline, transformation, convergence, integration, fusion, intelligence, interactivity, learning, adaptation, communication, collaboration, trust, accountability, transparency, governance, regulation, enforcement, justice, equity and inclusion, diversity and inclusivity, fairness and justice.\n",
      "\n",
      "In autonomous driverless driving (ADL), AI plays a pivotal role in enabling self-driving cars through machine learning models which learn from vast amounts of data. This includes analyzing driving patterns, road conditions, traffic signs, pedestrian movements, vehicle interactions, weather patterns and other factors to make optimal driving decisions. It can also identify potential hazards, obstacles and obstacles within driving range to prevent accidents or collisions. AI-driven autonomous vehicles can reduce traffic congestion, fuel consumption, air pollution, accident rates and fatalities. They also improve safety for passengers and pedestrians. The integration\n",
      "\n",
      "[Keyword Stats] count=7, present=['healthcare']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    LogitsProcessor,\n",
    "    LogitsProcessorList,\n",
    ")\n",
    "\n",
    "# ================== 1. Load an Open-Source Model ==================\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"  # Change if needed\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "dtype = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME} on {device}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=dtype,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    ").to(device)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# ================== 2. Keywords and Token IDs ==================\n",
    "keywords = [\n",
    "    \"large language models\",\n",
    "    \"artificial intelligence\",\n",
    "    \"healthcare\",\n",
    "    \"autonomous driving\",\n",
    "    \"intelligent customer service\",\n",
    "]\n",
    "\n",
    "focus_token_ids = set()\n",
    "for kw in keywords:\n",
    "    ids = tokenizer.encode(kw, add_special_tokens=False)\n",
    "    focus_token_ids.update(ids)\n",
    "\n",
    "focus_token_ids = torch.tensor(\n",
    "    sorted(focus_token_ids),\n",
    "    device=device,\n",
    "    dtype=torch.long,\n",
    ")\n",
    "\n",
    "print(f\"Focused token IDs: {focus_token_ids.tolist()}\")\n",
    "\n",
    "# ================== 3. Logits Processor ==================\n",
    "class KeywordBiasLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, token_ids: torch.Tensor, bias: float = 3.0):\n",
    "        self.token_ids = token_ids\n",
    "        self.bias = bias\n",
    "\n",
    "    def __call__(self, input_ids, scores):\n",
    "        scores[:, self.token_ids] += self.bias\n",
    "        return scores\n",
    "\n",
    "# ================== 4. Prompt Builder ==================\n",
    "def build_chat_prompt(user_prompt: str) -> str:\n",
    "    if hasattr(tokenizer, \"apply_chat_template\"):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_prompt}]\n",
    "        return tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "    else:\n",
    "        return f\"User: {user_prompt}\\nAssistant:\"\n",
    "\n",
    "# ================== 5. Text Generation ==================\n",
    "@torch.no_grad()\n",
    "def generate_text(prompt: str, use_bias: bool = False, bias: float = 3.0) -> str:\n",
    "    text = build_chat_prompt(prompt)\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    logits_processor = None\n",
    "    if use_bias:\n",
    "        logits_processor = LogitsProcessorList([\n",
    "            KeywordBiasLogitsProcessor(focus_token_ids, bias)\n",
    "        ])\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.05,\n",
    "        no_repeat_ngram_size=2,\n",
    "        logits_processor=logits_processor,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    generated_ids = output_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
    "    return tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "# ================== 6. Keyword Statistics ==================\n",
    "def count_keywords(text: str, keywords):\n",
    "    count = 0\n",
    "    present = []\n",
    "    for kw in keywords:\n",
    "        c = text.lower().count(kw.lower())\n",
    "        if c > 0:\n",
    "            count += c\n",
    "            present.append(kw)\n",
    "    return count, present\n",
    "\n",
    "# ================== 7. Test Prompt ==================\n",
    "test_prompt = (\n",
    "    \"Please discuss the future development trends of artificial intelligence \"\n",
    "    \"and large language models in a clear and natural manner, and analyze their \"\n",
    "    \"potential applications and challenges across specific industries such as \"\n",
    "    \"healthcare, autonomous driving, and intelligent customer service.\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 20 + \" Baseline Generation \" + \"=\" * 20)\n",
    "out1 = generate_text(test_prompt, use_bias=False)\n",
    "print(out1)\n",
    "c1, p1 = count_keywords(out1, keywords)\n",
    "print(f\"\\n[Keyword Stats] count={c1}, present={p1}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 20 + \" Keyword-Biased Generation \" + \"=\" * 20)\n",
    "out2 = generate_text(test_prompt, use_bias=True, bias=3.0)\n",
    "print(out2)\n",
    "c2, p2 = count_keywords(out2, keywords)\n",
    "print(f\"\\n[Keyword Stats] count={c2}, present={p2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8002d2",
   "metadata": {},
   "source": [
    "### 通过干预 Logits 引导模型聚焦关键信息\n",
    "\n",
    "对于像 Qwen 或 Llama 这样的先进自回归模型（Decoder-only Models），它们依赖自注意力机制来理解上下文。简而言之，模型在生成每个新词时，会回顾此前的所有文本，并从中提取相关信息。我们的目标是在这个“回顾”过程中施加影响，让模型更关注我们指定的关键内容。\n",
    "\n",
    "## 高级干预策略\n",
    "\n",
    "### 强力干预（The Hard Boost）\n",
    "\n",
    "最直接的方式是在目标 token 的 logits 上添加一个固定的正向偏置。这种方式干预效果明显，但可能影响文本的自然性，导致关键词重复出现。可通过 `no_repeat_ngram_size` 等参数缓解这一问题。\n",
    "\n",
    "### 温和引导（The Gentle Nudge）\n",
    "\n",
    "更精细的做法是采用加权融合策略，将原始 logits 与关键词偏置进行线性融合：\n",
    "\n",
    "```\n",
    "new_logits = original_logits * (1 - α) + entity_bias * α\n",
    "```\n",
    "\n",
    "其中，α 是一个介于 0 和 1 之间的融合因子，用于控制干预强度。α 越小，干预越温和，生成内容越自然。\n",
    "\n",
    "### 动态衰减\n",
    "\n",
    "还可根据生成阶段动态调整偏置值。例如，在生成初期给予较强干预，随后逐步减弱，使模型在后期拥有更多自由发挥的空间，从而在聚焦关键信息与保持多样性之间取得平衡。\n",
    "\n",
    "## 局限性\n",
    "\n",
    "- **过度聚焦风险**：可能导致生成内容变得狭隘、重复，缺乏创造性。\n",
    "- **计算开销**：虽然单次干预开销较小，但在复杂场景中频繁干预会略微增加推理延迟。\n",
    "\n",
    "## 与其他技术的协同\n",
    "\n",
    "强制聚焦并非孤立手段，它可与多种主流技术结合，实现更优效果：\n",
    "\n",
    "- **提示词工程（Prompt Engineering）**：先用高质量 Prompt 指明方向，再通过干预确保关键细节不丢失。\n",
    "- **RAG（检索增强生成）**：RAG 负责从外部知识库中检索关键信息，而干预技术则确保这些信息在最终输出中得以体现。\n",
    "- **LoRA / QLoRA 微调**：通过微调让模型掌握特定领域知识，再在推理时用干预技术引导模型聚焦具体任务。\n",
    "\n",
    "## 总结\n",
    "\n",
    "通过钩子（Hook）机制干预模型的 Logits 层，是一种强大、可解释的干预方式。它能够引导模型在生成过程中聚焦关键实体，提升输出的准确性与相关性。结合提示词工程、RAG 和微调技术，可以进一步增强干预效果，使其在实际应用中更加稳定、自然地服务于特定任务需求。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_clean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
