{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "139e7085",
   "metadata": {},
   "source": [
    "## 多模态任务怎么做评估？详解跨模态检索与生成的质量评价方法\n",
    "\n",
    "### 1. 评测之困\n",
    "\n",
    "#### 第一个痛点：多模态融合难\n",
    "\n",
    "例子：\n",
    "- 用户问：\"这个架构图中数据流向是怎样的？\"\n",
    "- 正确答案需要：文字描述 + 图中箭头指向 + 具体组件名称\n",
    "\n",
    "#### 第二个痛点：检索不准\n",
    "\n",
    "多模态检索比文本检索复杂得多。系统需要在图片、表格、文档中找到相关信息，然后还要判断这些信息是否真的能回答用户问题。\n",
    "\n",
    "#### 第三个痛点：大模型瞎编\n",
    "\n",
    "大模型容易编造不存在的信息，或者张冠李戴地标错出处。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3684c7ee",
   "metadata": {},
   "source": [
    "### 2. 指标解析：评测参数的作用机制\n",
    "\n",
    "看这个例子：\n",
    "- 答案：九寨沟最佳游览时间是春季，主要看樱花\n",
    "- 标准答案：九寨沟最佳游览时间是秋季，主要看彩林\n",
    "\n",
    "传统相似度算法会给高分，因为都提到\"九寨沟\"、\"最佳游览时间\"。但事实完全错误：时间错了，景观也错了。\n",
    "\n",
    "\n",
    "#### 2.1 事实准确度\n",
    "\n",
    "1. 观点拆解：\n",
    "  - 答案观点：[\"九寨沟适合春季游览\", \"主要景观是樱花\"]\n",
    "  - 标准观点：[\"九寨沟适合秋季游览\", \"主要景观是彩林\"]\n",
    "    \n",
    "2. 事实核查：逐一比较每个观点\n",
    "  - \"春季游览\" vs \"秋季游览\" ✗ 冲突\n",
    "  - \"樱花\" vs \"彩林\" ✗ 冲突\n",
    "    \n",
    "3. 分数计算：一致观点数 / 总观点数 = 0/2 = 0\n",
    "  \n",
    "这才真正反映了事实层面的准确性。\n",
    "\n",
    "#### 2.2 Context Recall：检索召回的完整性\n",
    "\n",
    "用户问：\"去九寨沟需要准备什么？\"\n",
    "\n",
    "标准答案：需要准备防寒衣物、防晒用品和高原反应药物。\n",
    "\n",
    "系统检索到的上下文：\n",
    "- 文档1：九寨沟海拔较高，需准备防寒衣物\n",
    "- 文档2：稻城亚丁旅游攻略，需要氧气瓶\n",
    "- 文档3：九寨沟门票价格信息\n",
    "  \n",
    "Context Recall计算：\n",
    "1. 关键信息提取：[\"防寒衣物\", \"防晒用品\", \"高原反应药物\"]\n",
    "2. 上下文匹配：\n",
    "  - \"防寒衣物\" ✓ 文档1中找到\n",
    "  - \"防晒用品\" ✗ 未找到\n",
    "  - \"高原反应药物\" ✗ 未找到\n",
    "3. 召回率：1/3 ≈ 0.33\n",
    "  \n",
    "检索遗漏了67%的关键信息。\n",
    "\n",
    "#### 2.3 Context Precision：检索精准度量化\n",
    "\n",
    "同样的例子，系统检索到3个文档：\n",
    "- 文档1（防寒衣物）：相关 ✓\n",
    "- 文档2（稻城亚丁攻略）：不相关 ✗\n",
    "- 文档3（门票价格）：不相关 ✗\n",
    "  \n",
    "Context Precision = 1/3 ≈ 0.33\n",
    "\n",
    "67%都是噪音，会误导大模型生成错误答案。\n",
    "\n",
    "#### 2.4 指标协同与权衡\n",
    "\n",
    "三个指标各有分工：\n",
    "- 事实准确度：确保答案事实正确\n",
    "- Context Recall：确保信息无遗漏\n",
    "- Context Precision：确保无噪音干扰\n",
    "  \n",
    "关键是平衡：\n",
    "- 提高召回→更多文档→可能引入噪音\n",
    "- 提高精准→严格筛选→可能遗漏信息\n",
    "  \n",
    "权重设计示例：\n",
    "- 答案准确性：50%\n",
    "- 来源准确性：50%\n",
    "  \n",
    "为什么来源这么重要？用户问九寨沟攻略，系统说\"根据《云南旅游指南》第15页\"，但实际在《四川旅游手册》里，用户查证时发现对不上，信任度立刻下降。\n",
    "\n",
    "多模态RAG评测本质是多目标优化：在准确性、完整性、精准度之间找平衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb742f",
   "metadata": {},
   "source": [
    "## 3. 实战指南：基于Ragas的多模态RAG评测实践\n",
    "\n",
    "### 3.1 多模态测试数据构建\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eccdc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain_community\n",
    "!pip install datasets\n",
    "!pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2728ef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_samples = {\n",
    "    'question': [\n",
    "        '这张九寨沟地图中标注的五花海在哪个位置？',\n",
    "        '这张九寨沟地图中标注的五花海在哪个位置？',\n",
    "        '这张九寨沟地图中标注的五花海在哪个位置？'\n",
    "    ],\n",
    "    'answer': [\n",
    "        '抱歉，我无法从提供的信息中确定五花海的具体位置。建议查看更详细的地图资料。',\n",
    "        '五花海位于九寨沟景区的北部区域',\n",
    "        '根据地图显示，五花海位于日则沟的中段，距离诺日朗瀑布约2公里'\n",
    "    ],\n",
    "    'ground_truth': [\n",
    "        '五花海位于日则沟中段，是九寨沟最美的海子之一',\n",
    "        '五花海位于日则沟中段，是九寨沟最美的海子之一',\n",
    "        '五花海位于日则沟中段，是九寨沟最美的海子之一'\n",
    "    ],\n",
    "    # 标准contexts格式（用于Ragas标准指标）\n",
    "    'contexts': [\n",
    "        [\n",
    "            '九寨沟景区分为三条沟：树正沟、日则沟、则查洼沟',\n",
    "            '图像描述：九寨沟景区总览图，但图片模糊不清，无法清晰看到五花海位置'\n",
    "        ],\n",
    "        [\n",
    "            '五花海是九寨沟著名景点',\n",
    "            '图像描述：九寨沟北部区域地图，显示了部分景点，包括五花海大致区域'\n",
    "        ],\n",
    "        [\n",
    "            '日则沟是九寨沟三条主沟之一',\n",
    "            '图像描述：九寨沟详细地图，清晰标注了五花海在日则沟中段的位置，距离诺日朗瀑布约2公里'\n",
    "        ]\n",
    "    ],\n",
    "    # 多模态contexts格式（用于自定义指标）\n",
    "    'multimodal_contexts': [\n",
    "        [\n",
    "            {'type': 'text', 'content': '九寨沟景区分为三条沟：树正沟、日则沟、则查洼沟'},\n",
    "            {'type': 'image', 'description': '九寨沟景区总览图，但图片模糊不清'}\n",
    "        ],\n",
    "        [\n",
    "            {'type': 'text', 'content': '五花海是九寨沟著名景点'},\n",
    "            {'type': 'image', 'description': '九寨沟北部区域地图，显示了部分景点'}\n",
    "        ],\n",
    "        [\n",
    "            {'type': 'text', 'content': '日则沟是九寨沟三条主沟之一'},\n",
    "            {'type': 'image', 'description': '九寨沟详细地图，清晰标注了五花海在日则沟中段的位置'}\n",
    "        ]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8324f96",
   "metadata": {},
   "source": [
    "### 3.2 多模态评测指标扩展"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d4211a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 多模态RAG评测系统测试 ===\n",
      "数据集验证:\n",
      "  样本数量: 3\n",
      "  字段: ['question', 'answer', 'ground_truth', 'contexts', 'multimodal_contexts']\n",
      "=== 测试类接口（Ragas兼容） ===\n",
      "多模态上下文召回率: 0.000\n",
      "跨模态对齐度: 0.267\n",
      "视觉理解准确率: 0.300\n",
      "综合评分: 0.189\n",
      "\n",
      "=== 测试独立函数接口 ===\n",
      "\n",
      "样本 1:\n",
      "  问题: 这张九寨沟地图中标注的五花海在哪个位置？\n",
      "  答案: 抱歉，我无法从提供的信息中确定五花海的具体位置。建议查看更详细的地图资料。...\n",
      "  多模态检索:\n",
      "    文本相关性: 0.000\n",
      "    图像相关性: 0.000\n",
      "    融合效果: 0.000\n",
      "    总体评分: 0.000\n",
      "  视觉理解: 0.000\n",
      "  跨模态对齐: 0.000\n",
      "\n",
      "样本 2:\n",
      "  问题: 这张九寨沟地图中标注的五花海在哪个位置？\n",
      "  答案: 五花海位于九寨沟景区的北部区域...\n",
      "  多模态检索:\n",
      "    文本相关性: 0.000\n",
      "    图像相关性: 0.000\n",
      "    融合效果: 0.000\n",
      "    总体评分: 0.000\n",
      "  视觉理解: 0.200\n",
      "  跨模态对齐: 0.200\n",
      "\n",
      "样本 3:\n",
      "  问题: 这张九寨沟地图中标注的五花海在哪个位置？\n",
      "  答案: 根据地图显示，五花海位于日则沟的中段，距离诺日朗瀑布约2公里...\n",
      "  多模态检索:\n",
      "    文本相关性: 0.000\n",
      "    图像相关性: 0.000\n",
      "    融合效果: 0.000\n",
      "    总体评分: 0.000\n",
      "  视觉理解: 0.700\n",
      "  跨模态对齐: 0.600\n",
      "\n",
      "=== 接口结果对比 ===\n",
      "=== 测试类接口（Ragas兼容） ===\n",
      "多模态上下文召回率: 0.000\n",
      "跨模态对齐度: 0.267\n",
      "视觉理解准确率: 0.300\n",
      "综合评分: 0.189\n",
      "\n",
      "=== 测试独立函数接口 ===\n",
      "\n",
      "样本 1:\n",
      "  问题: 这张九寨沟地图中标注的五花海在哪个位置？\n",
      "  答案: 抱歉，我无法从提供的信息中确定五花海的具体位置。建议查看更详细的地图资料。...\n",
      "  多模态检索:\n",
      "    文本相关性: 0.000\n",
      "    图像相关性: 0.000\n",
      "    融合效果: 0.000\n",
      "    总体评分: 0.000\n",
      "  视觉理解: 0.000\n",
      "  跨模态对齐: 0.000\n",
      "\n",
      "样本 2:\n",
      "  问题: 这张九寨沟地图中标注的五花海在哪个位置？\n",
      "  答案: 五花海位于九寨沟景区的北部区域...\n",
      "  多模态检索:\n",
      "    文本相关性: 0.000\n",
      "    图像相关性: 0.000\n",
      "    融合效果: 0.000\n",
      "    总体评分: 0.000\n",
      "  视觉理解: 0.200\n",
      "  跨模态对齐: 0.200\n",
      "\n",
      "样本 3:\n",
      "  问题: 这张九寨沟地图中标注的五花海在哪个位置？\n",
      "  答案: 根据地图显示，五花海位于日则沟的中段，距离诺日朗瀑布约2公里...\n",
      "  多模态检索:\n",
      "    文本相关性: 0.000\n",
      "    图像相关性: 0.000\n",
      "    融合效果: 0.000\n",
      "    总体评分: 0.000\n",
      "  视觉理解: 0.700\n",
      "  跨模态对齐: 0.600\n",
      "\n",
      "结果对比:\n",
      "多模态召回 - 类接口: 0.000, 函数接口: 0.000\n",
      "视觉理解 - 类接口: 0.300, 函数接口: 0.300\n",
      "跨模态对齐 - 类接口: 0.267, 函数接口: 0.267\n",
      "\n",
      "接口一致性: ✅ 一致\n",
      "\n",
      "=== 期望结果分析 ===\n",
      "\n",
      "样本 1 (拒绝回答):\n",
      "实际结果:\n",
      "  多模态召回: 0.000\n",
      "  跨模态对齐: 0.000\n",
      "  视觉理解: 0.000\n",
      "期望结果:\n",
      "  多模态召回: 0.000\n",
      "  跨模态对齐: 0.000\n",
      "  视觉理解: 0.000\n",
      "差异:\n",
      "  多模态召回: 0.000\n",
      "  跨模态对齐: 0.000\n",
      "  视觉理解: 0.000\n",
      "\n",
      "样本 2 (部分正确):\n",
      "实际结果:\n",
      "  多模态召回: 0.000\n",
      "  跨模态对齐: 0.200\n",
      "  视觉理解: 0.200\n",
      "期望结果:\n",
      "  多模态召回: 0.400\n",
      "  跨模态对齐: 0.300\n",
      "  视觉理解: 0.200\n",
      "差异:\n",
      "  多模态召回: 0.400\n",
      "  跨模态对齐: 0.100\n",
      "  视觉理解: 0.000\n",
      "\n",
      "样本 3 (完全正确):\n",
      "实际结果:\n",
      "  多模态召回: 0.000\n",
      "  跨模态对齐: 0.600\n",
      "  视觉理解: 0.700\n",
      "期望结果:\n",
      "  多模态召回: 0.900\n",
      "  跨模态对齐: 0.800\n",
      "  视觉理解: 0.900\n",
      "差异:\n",
      "  多模态召回: 0.900\n",
      "  跨模态对齐: 0.200\n",
      "  视觉理解: 0.200\n"
     ]
    }
   ],
   "source": [
    "!python ./test_multimodal_evaluation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a41665",
   "metadata": {},
   "source": [
    "### 3.3 多模态评测的核心挑战\n",
    "\n",
    "1. 跨模态检索评估\n",
    "\n",
    "```python\n",
    "\n",
    "def evaluate_multimodal_retrieval(query: str, retrieved_contexts: Dict[str, List[str]], \n",
    "                                ground_truth: str = \"\", answer: str = \"\") -> Dict[str, float]:\n",
    "    \"\"\"评估多模态检索质量\"\"\"\n",
    "    \n",
    "    def evaluate_cross_modal_fusion(text_contexts: List[str], image_contexts: List[str]) -> float:\n",
    "        \"\"\"评估跨模态融合效果\"\"\"\n",
    "        if not text_contexts or not image_contexts:\n",
    "            return 0.1\n",
    "        \n",
    "        text_content = ' '.join(text_contexts)\n",
    "        image_content = ' '.join(image_contexts)\n",
    "        return calculate_semantic_overlap(text_content, image_content)\n",
    "    \n",
    "```\n",
    "\n",
    "2. 视觉理解准确性评估\n",
    "\n",
    "```python\n",
    "def evaluate_visual_understanding(question: str, image_descriptions: List[str], \n",
    "                                answer: str, ground_truth: str) -> float:\n",
    "    \"\"\"评估系统对图像内容的理解准确性\"\"\"\n",
    "    \n",
    "    if not image_descriptions:\n",
    "        return 0.0\n",
    "    \n",
    "    # 提取问题中的视觉要素\n",
    "    visual_elements = extract_visual_elements(question)\n",
    "    \n",
    "    def check_visual_element_understanding(element: str, answer: str, ground_truth: str) -> float:\n",
    "        \"\"\"检查单个视觉要素的理解准确性\"\"\"\n",
    "        answer_has_element = element in answer\n",
    "        truth_has_element = element in ground_truth\n",
    "        \n",
    "        if answer_has_element and truth_has_element:\n",
    "            return 1.0\n",
    "        elif not answer_has_element and not truth_has_element:\n",
    "            return 0.5\n",
    "        else:\n",
    "            return 0.0\n",
    "    \n",
    "    # 检查答案是否正确理解了图像内容\n",
    "    understanding_scores = []\n",
    "    for element in visual_elements:\n",
    "        score = check_visual_element_understanding(element, answer, ground_truth)\n",
    "        understanding_scores.append(score)\n",
    "    \n",
    "    if not understanding_scores:\n",
    "        understanding_scores = [0.5]  # 默认分数\n",
    "    \n",
    "    base_score = sum(understanding_scores) / len(understanding_scores)\n",
    "```\n",
    "\n",
    "3. 图文对齐度评估\n",
    "\n",
    "```python\n",
    "def evaluate_cross_modal_alignment(contexts: List[Dict[str, Any]], answer: str = \"\") -> float:\n",
    "    \"\"\"评估检索到的图文内容是否对齐\"\"\"\n",
    "    \n",
    "    text_contexts = []\n",
    "    image_contexts = []\n",
    "    \n",
    "    for context in contexts:\n",
    "        if isinstance(context, dict):\n",
    "            if context.get('type') == 'text':\n",
    "                text_contexts.append(context.get('content', ''))\n",
    "            elif context.get('type') == 'image':\n",
    "                image_contexts.append(context.get('description', ''))\n",
    "    \n",
    "    if not text_contexts or not image_contexts:\n",
    "        return 0.1\n",
    "    \n",
    "    def calculate_image_text_alignment(image_description: str, text_contents: List[str]) -> float:\n",
    "        \"\"\"计算图像描述与文本内容的对齐度\"\"\"\n",
    "        combined_text = ' '.join(text_contents)\n",
    "        return calculate_semantic_overlap(image_description, combined_text)\n",
    "    \n",
    "    alignment_scores = []\n",
    "    for img_desc in image_contexts:\n",
    "        alignment_score = calculate_image_text_alignment(img_desc, text_contexts)\n",
    "        alignment_scores.append(alignment_score)\n",
    "    \n",
    "    base_alignment = sum(alignment_scores) / len(alignment_scores) if alignment_scores else 0.0\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "通过这套多模态评测体系，你就能真正评估系统处理图文混合内容的能力，而不仅仅是传统的文本RAG评测。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d673c90",
   "metadata": {},
   "source": [
    "## 4. 优化之道：让评测指标更好地服务业务决策\n",
    "\n",
    "### 4.1 风险等级划分：\n",
    "\n",
    "```python\n",
    "\n",
    "def classify_business_risk(scores):\n",
    "    \"\"\"将评测分数转化为业务风险等级\"\"\"\n",
    "    \n",
    "    if scores['visual_accuracy'] < 0.3:\n",
    "        return \"高风险：用户会发现系统看不懂图片\"\n",
    "    elif scores['cross_modal_alignment'] < 0.5:\n",
    "        return \"中风险：答案可能图文不符\"\n",
    "    elif scores['context_recall'] < 0.7:\n",
    "        return \"低风险：信息不够全面但基本可用\"\n",
    "    else:\n",
    "        return \"可接受：达到上线标准\"\n",
    "\n",
    "```\n",
    "\n",
    "业务影响量化：\n",
    "- Visual Accuracy < 0.3 → 用户投诉率可能增加40%\n",
    "- Cross Modal Alignment < 0.5 → 用户信任度下降25%\n",
    "- Context Recall < 0.7 → 用户满意度降低15%\n",
    "\n",
    "\n",
    "### 4.2 权重设计的业务逻辑\n",
    "\n",
    "旅游咨询场景的权重设计：\n",
    "\n",
    "```python\n",
    "tourism_weights = {\n",
    "    'visual_accuracy': 0.4,      # 看懂地图、景点图片最重要\n",
    "    'context_recall': 0.3,       # 信息全面性次之\n",
    "    'cross_modal_alignment': 0.2, # 图文一致性\n",
    "    'context_precision': 0.1      # 精准度相对不那么关键\n",
    "}\n",
    "\n",
    "# 综合评分计算\n",
    "def calculate_business_score(scores, weights):\n",
    "    return sum(scores[metric] * weight for metric, weight in weights.items())\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### 4.3 持续优化的闭环机制\n",
    "\n",
    "评测不是一次性的，而是要建立持续优化的闭环。\n",
    "\n",
    "1. 建立评测基线\n",
    "\n",
    "```python\n",
    "# 建立不同场景的评测基线\n",
    "baseline_scores = {\n",
    "    'tourism_consultation': {\n",
    "        'visual_accuracy': 0.75,\n",
    "        'context_recall': 0.80,\n",
    "        'cross_modal_alignment': 0.70,\n",
    "        'context_precision': 0.65\n",
    "    },\n",
    "    'document_qa': {\n",
    "        'visual_accuracy': 0.85,  # 文档理解要求更高\n",
    "        'context_recall': 0.90,\n",
    "        'cross_modal_alignment': 0.80,\n",
    "        'context_precision': 0.85\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "2. 监控指标变化趋势\n",
    "\n",
    "```python\n",
    "def monitor_performance_trend(current_scores, historical_scores):\n",
    "    \"\"\"监控性能变化趋势\"\"\"\n",
    "    trends = {}\n",
    "    \n",
    "    for metric in current_scores:\n",
    "        recent_avg = np.mean(historical_scores[metric][-7:])  # 最近7天平均\n",
    "        trend = (current_scores[metric] - recent_avg) / recent_avg\n",
    "        \n",
    "        if trend < -0.05:\n",
    "            trends[metric] = \"下降趋势，需要关注\"\n",
    "        elif trend > 0.05:\n",
    "            trends[metric] = \"上升趋势，效果良好\"\n",
    "        else:\n",
    "            trends[metric] = \"稳定\"\n",
    "    \n",
    "    return trends\n",
    "```\n",
    "\n",
    "3. 自动化优化建议\n",
    "\n",
    "```python\n",
    "def generate_optimization_suggestions(scores):\n",
    "    \"\"\"基于评测结果生成优化建议\"\"\"\n",
    "    suggestions = []\n",
    "    \n",
    "    if scores['visual_accuracy'] < 0.6:\n",
    "        suggestions.append({\n",
    "            'priority': 'high',\n",
    "            'action': '升级视觉理解模型',\n",
    "            'expected_improvement': '视觉准确率提升20-30%',\n",
    "            'implementation': '考虑使用GPT-4V或Claude-3等更强的多模态模型'\n",
    "        })\n",
    "    \n",
    "    if scores['context_recall'] < 0.7:\n",
    "        suggestions.append({\n",
    "            'priority': 'medium',\n",
    "            'action': '优化检索策略',\n",
    "            'expected_improvement': '召回率提升15-25%',\n",
    "            'implementation': '增加检索候选数量，调整相似度阈值'\n",
    "        })\n",
    "    \n",
    "    if scores['cross_modal_alignment'] < 0.5:\n",
    "        suggestions.append({\n",
    "            'priority': 'medium',\n",
    "            'action': '增加图文对齐训练',\n",
    "            'expected_improvement': '对齐度提升30-40%',\n",
    "            'implementation': '使用更多图文配对数据进行微调'\n",
    "        })\n",
    "    \n",
    "    return suggestions\n",
    "```\n",
    "\n",
    "### 4.4 评测结果的产品决策转化\n",
    "\n",
    "最终，评测要服务于产品决策。\n",
    "\n",
    "- 上线决策矩阵\n",
    "- A/B测试设计\n",
    "\n",
    "\n",
    "随着业务发展，评测体系也要不断演进。\n",
    "\n",
    "评测指标的动态调整：\n",
    "- 初期：重点关注基础功能（能不能看懂图片）\n",
    "- 成长期：关注用户体验（答案是否全面准确）\n",
    "- 成熟期：关注细节优化（响应速度、个性化程度）\n",
    "\n",
    "### 小结\n",
    "\n",
    "**多模态RAG的评测，最终目的不是为了得到一个漂亮的分数，而是要建立一套能够持续指导产品优化、降低业务风险、提升用户体验的完整体系。**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
