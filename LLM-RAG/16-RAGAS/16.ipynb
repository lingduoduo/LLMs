{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "023c1d22",
   "metadata": {},
   "source": [
    "# å¦‚ä½•ç§‘å­¦è°ƒèŠ‚åˆ‡ç‰‡é•¿åº¦ä¸æ»‘åŠ¨çª—å£ï¼Ÿç»“åˆå€’æ’ç´¢å¼•ä¸å‘é‡ç´¢å¼•å¯¹æ¯”ä¼˜åŒ–\n",
    "\n",
    "## ä¸€ã€é—®é¢˜å¼•å…¥ï¼šå¦‚ä½•è‡ªåŠ¨åŒ–è¯„ä¼°åˆ‡ç‰‡ç­–ç•¥ä¸ç´¢å¼•æ–¹å¼ï¼Ÿ\n",
    "åœ¨æ„å»º RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿæ—¶ï¼Œæ–‡æœ¬åˆ‡ç‰‡ç­–ç•¥ï¼ˆchunking strategyï¼‰å’Œç´¢å¼•æ–¹æ³•éƒ½æ˜¯å½±å“ç³»ç»Ÿæ€§èƒ½çš„å…³é”®å› ç´ ä¹‹ä¸€ã€‚ä¸å½“çš„åˆ‡ç‰‡é•¿åº¦æˆ–ç´¢å¼•è®¾ç½®ï¼Œå¯èƒ½å¯¼è‡´ï¼š\n",
    "- æ£€ç´¢ä¸å®Œæ•´ï¼ˆä¸Šä¸‹æ–‡å‰²è£‚ï¼‰\n",
    "- å†—ä½™ä¿¡æ¯è¿‡å¤šï¼ˆå½±å“ç”Ÿæˆè´¨é‡ï¼‰\n",
    "- è¯­ä¹‰è¡¨è¾¾ä¸å®Œæ•´ï¼ˆå½±å“å‘é‡åŒ¹é…æ•ˆæœï¼‰\n",
    "\n",
    "å› æ­¤æˆ‘ä»¬éœ€è¦æœ‰æ•ˆè¯„ä¼° RAG ç³»ç»Ÿçš„æ€»ä½“èƒ½åŠ›å’Œæ¯ä¸€éƒ¨åˆ†èƒ½åŠ›ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## äºŒã€å®æˆ˜å‡†å¤‡ï¼šä½¿ç”¨ RAGAS è¿›è¡Œç³»ç»Ÿè¯„ä¼°\n",
    "### 2.1 RAGAS ç®€ä»‹ä¸æ ¸å¿ƒæŒ‡æ ‡\n",
    "\n",
    "RAGAS æ˜¯ä¸€ä¸ªä¸“ä¸º RAG ç³»ç»Ÿè®¾è®¡çš„è¯„ä¼°å·¥å…·ï¼Œæä¾›ä»¥ä¸‹æ ¸å¿ƒæŒ‡æ ‡ï¼š\n",
    "\n",
    "- Answer Relevance ï¼šç”Ÿæˆç­”æ¡ˆæ˜¯å¦ä¸é—®é¢˜ç›¸å…³ï¼Ÿ\n",
    "- Context Precision ï¼šæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ˜¯å¦ç›¸å…³ï¼Ÿ\n",
    "- Context Recall ï¼šæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ˜¯å¦åŒ…å«å›ç­”æ‰€éœ€ä¿¡æ¯ï¼Ÿ\n",
    "- Faithfulness ï¼šç”Ÿæˆç­”æ¡ˆæ˜¯å¦åŸºäºæ£€ç´¢åˆ°çš„å†…å®¹ï¼Ÿ\n",
    "\n",
    "### 2.2 RAGAS æµ‹è¯„æµç¨‹\n",
    "\n",
    "1. æ„å»ºæµ‹è¯•æ•°æ®é›†ï¼šå‡†å¤‡ä¸€ç»„é—®é¢˜ã€çœŸå®ç­”æ¡ˆã€æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ã€‚\n",
    "2. è¿è¡Œ RAGAS è¯„ä¼°ï¼šä½¿ç”¨ RAGAS å·¥å…·è®¡ç®—å„é¡¹æŒ‡æ ‡ã€‚\n",
    "3. åˆ†æç»“æœï¼šæ ¹æ®è¯„ä¼°ç»“æœè°ƒæ•´åˆ‡ç‰‡ç­–ç•¥ã€ç´¢å¼•ç­–ç•¥ç­‰ï¼Œä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ã€‚\n",
    "\n",
    "### 2.3 å®æˆ˜æ¼”ç»ƒï¼šæ­å»º RAGAS è¯„ä¼°æµç¨‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26915d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a08ad79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebb05db9fd147fb876e58d59e467ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_relevancy': 0.8813, 'context_precision': 1.0000, 'context_recall': 1.0000, 'faithfulness': 0.7500}\n"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import answer_relevancy, context_precision, context_recall, faithfulness\n",
    "from ragas import evaluate\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# æ„å»ºæµ‹è¯•æ•°æ®é›†\n",
    "data = {\n",
    "    \"question\": [\"RAG ç³»ç»Ÿå¦‚ä½•ä¼˜åŒ–åˆ‡ç‰‡ç­–ç•¥ï¼Ÿ\", \"å‘é‡ç´¢å¼•å’Œå€’æ’ç´¢å¼•æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ\"],\n",
    "    \"answer\": [\"å¯ä»¥é€šè¿‡ RAGAS æµ‹è¯„å·¥å…·è¯„ä¼°ä¸åŒåˆ‡ç‰‡ç­–ç•¥çš„æ€§èƒ½ï¼Œä¼˜åŒ–åˆ‡ç‰‡é•¿åº¦å’Œæ»‘åŠ¨çª—å£é…ç½®ã€‚\", \"å‘é‡ç´¢å¼•åŸºäºè¯­ä¹‰åŒ¹é…ï¼Œè€Œå€’æ’ç´¢å¼•åŸºäºå…³é”®è¯åŒ¹é…ã€‚\"],\n",
    "    \"contexts\": [[\"RAGAS æä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ Answer Relevanceã€Context Precision ç­‰ã€‚\", \"åˆ‡ç‰‡é•¿åº¦å’Œæ»‘åŠ¨çª—å£é…ç½®å¯¹æ£€ç´¢æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚\"], [\"å€’æ’ç´¢å¼•é€‚ç”¨äºå…³é”®è¯åŒ¹é…ï¼Œè€Œå‘é‡ç´¢å¼•é€‚ç”¨äºè¯­ä¹‰åŒ¹é…ã€‚\", \"å‘é‡ç´¢å¼•éœ€è¦æ›´å¤šè®¡ç®—èµ„æºï¼Œä½†èƒ½æ•æ‰è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚\"]],\n",
    "    \"ground_truth\": [\"RAGAS æä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ Answer Relevanceã€Context Precision ç­‰ã€‚åˆ‡ç‰‡é•¿åº¦å’Œæ»‘åŠ¨çª—å£é…ç½®å¯¹æ£€ç´¢æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚\", \"å€’æ’ç´¢å¼•é€‚ç”¨äºå…³é”®è¯åŒ¹é…ï¼Œè€Œå‘é‡ç´¢å¼•é€‚ç”¨äºè¯­ä¹‰åŒ¹é…ã€‚å‘é‡ç´¢å¼•éœ€è¦æ›´å¤šè®¡ç®—èµ„æºï¼Œä½†èƒ½æ•æ‰è¯­ä¹‰ç›¸ä¼¼æ€§ã€‚\"]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "\n",
    "# æ‰§è¡Œè¯„ä¼°\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[answer_relevancy, context_precision, context_recall, faithfulness]\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289e3cca",
   "metadata": {},
   "source": [
    "## ä¸‰ã€å¯¹æ¯”åˆ†æï¼šå€’æ’ç´¢å¼• vs å‘é‡ç´¢å¼•\n",
    "### 3.1 å€’æ’ç´¢å¼•ï¼ˆInverted Indexï¼‰\n",
    "\n",
    "é€‚ç”¨åœºæ™¯ï¼šå…³é”®è¯åŒ¹é…ã€å¿«é€Ÿæ£€ç´¢\n",
    "- âœ… é«˜æ•ˆæ£€ç´¢\n",
    "- âœ… æ”¯æŒå¸ƒå°”æŸ¥è¯¢\n",
    "- âŒ è¯­ä¹‰ç†è§£å¼±\n",
    "- âŒ å¯¹å…³é”®è¯ä¾èµ–å¼º\n",
    "\n",
    "### 3.2 å‘é‡ç´¢å¼•ï¼ˆVector Indexï¼‰\n",
    "\n",
    "é€‚ç”¨åœºæ™¯ï¼šè¯­ä¹‰åŒ¹é…ã€æ¨¡ç³Šæ£€ç´¢\n",
    "- âœ… è¯­ä¹‰ç†è§£èƒ½åŠ›å¼º\n",
    "- âœ… æ”¯æŒæ¨¡ç³ŠåŒ¹é…\n",
    "- âŒ è®¡ç®—æˆæœ¬é«˜\n",
    "- âŒ å¯¹åˆ‡ç‰‡é•¿åº¦æ•æ„Ÿ\n",
    "\n",
    "### 3.3 å®æˆ˜å¯¹æ¯”å®éªŒ\n",
    "\n",
    "ä½¿ç”¨ RAGAS è¯„ä¼°ä¸åŒç´¢å¼•æ–¹å¼ä¸‹çš„æ€§èƒ½è¡¨ç°ï¼ŒéªŒè¯å‘é‡ç´¢å¼•åœ¨è¯­ä¹‰åŒ¹é…åœºæ™¯ä¸­çš„ä¼˜åŠ¿ã€‚\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678bd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åº“\n",
    "%pip install ragas pandas datasets sentence-transformers scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f1c55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b890530574c64d7cb13521f81def7ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  retrieval_method        question  context_precision  context_recall  \\\n",
      "0   Inverted Index   RAGASæœ‰å“ªäº›è¯„ä¼°æŒ‡æ ‡ï¼Ÿ                0.0             0.0   \n",
      "1     Vector Index   RAGASæœ‰å“ªäº›è¯„ä¼°æŒ‡æ ‡ï¼Ÿ                0.0             0.0   \n",
      "2   Inverted Index  å¦‚ä½•æ ¹æ®æ„æ€æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£ï¼Ÿ                0.0             0.0   \n",
      "3     Vector Index  å¦‚ä½•æ ¹æ®æ„æ€æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£ï¼Ÿ                1.0             1.0   \n",
      "\n",
      "   faithfulness  answer_relevancy  \n",
      "0      0.000000          0.000000  \n",
      "1      0.666667          0.761393  \n",
      "2      0.000000          0.000000  \n",
      "3      0.600000          0.961128  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_recall, context_precision\n",
    "import torch\n",
    "\n",
    "# 1. æ„å»ºæ–‡æ¡£åº“ (Corpus)\n",
    "# æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªå°å‹çš„çŸ¥è¯†åº“ï¼Œæ£€ç´¢å™¨å°†ä»è¿™é‡Œå¯»æ‰¾ç­”æ¡ˆã€‚\n",
    "corpus = [\n",
    "    \"RAGASæ˜¯ä¸€ä¸ªè¯„ä¼°æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿæ€§èƒ½çš„æ¡†æ¶ã€‚\",\n",
    "    \"RAGASæä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œä¾‹å¦‚ç­”æ¡ˆç›¸å…³æ€§ (Answer Relevance) å’Œä¸Šä¸‹æ–‡ç²¾åº¦ (Context Precision)ã€‚\",\n",
    "    \"ä¼˜åŒ–åˆ‡ç‰‡ç­–ç•¥å¯¹æå‡æ£€ç´¢æ€§èƒ½è‡³å…³é‡è¦ï¼ŒåŒ…æ‹¬è°ƒæ•´å—å¤§å° (chunk size) å’Œé‡å  (overlap)ã€‚\",\n",
    "    \"å‘é‡ç´¢å¼•åˆ©ç”¨åµŒå…¥æŠ€æœ¯ï¼Œèƒ½æ•æ‰æ–‡æœ¬çš„è¯­ä¹‰ç›¸ä¼¼æ€§ï¼Œé€‚åˆå¤„ç†æ¦‚å¿µåŒ¹é…ã€‚\",\n",
    "    \"å€’æ’ç´¢å¼•é€šè¿‡å…³é”®è¯æ˜ å°„æ–‡æ¡£ï¼Œæ£€ç´¢é€Ÿåº¦å¿«ï¼Œéå¸¸é€‚åˆå…³é”®è¯æœç´¢ã€‚\",\n",
    "    \"è¯­ä¹‰æœç´¢ä¸ä¾èµ–äºç²¾ç¡®çš„å…³é”®è¯ï¼Œè€Œæ˜¯ç†è§£æŸ¥è¯¢èƒŒåçš„æ„å›¾ã€‚\",\n",
    "]\n",
    "\n",
    "# 2. å®ç°ä¸¤ç§æ£€ç´¢ç­–ç•¥\n",
    "\n",
    "#ç­–ç•¥ä¸€ï¼šå€’æ’ç´¢å¼• (Inverted Index) - åŸºäº TF-IDF\n",
    "# è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„å…³é”®è¯åŒ¹é…æ–¹æ³•ã€‚\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "def retrieve_with_inverted_index(query, top_k=2):\n",
    "    \"\"\"ä½¿ç”¨å€’æ’ç´¢å¼• (TF-IDF) æ£€ç´¢ä¸Šä¸‹æ–‡\"\"\"\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    scores = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    # è·å–å¾—åˆ†æœ€é«˜çš„ top_k ä¸ªæ–‡æ¡£çš„ç´¢å¼•\n",
    "    top_k_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    return [corpus[i] for i in top_k_indices if scores[i] > 0]\n",
    "\n",
    "# ç­–ç•¥äºŒï¼šå‘é‡ç´¢å¼• (Vector Index) - åŸºäº Sentence Transformers\n",
    "# è¿™æ˜¯ä¸€ä¸ªç°ä»£çš„è¯­ä¹‰åŒ¹é…æ–¹æ³•ã€‚\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "#########  GPU  Only ############\n",
    "# def retrieve_with_vector_index(query, top_k=2):\n",
    "#     \"\"\"ä½¿ç”¨å‘é‡ç´¢å¼• (Sentence Transformer) æ£€ç´¢ä¸Šä¸‹æ–‡\"\"\"\n",
    "#     query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "#     # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "#     scores = cosine_similarity(query_embedding.unsqueeze(0), corpus_embeddings)[0]\n",
    "#     # è·å–å¾—åˆ†æœ€é«˜çš„ top_k ä¸ªæ–‡æ¡£çš„ç´¢å¼•\n",
    "#     top_k_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "#     return [corpus[i] for i in top_k_indices]\n",
    "\n",
    "### CPU support ###\n",
    "def retrieve_with_vector_index(query, top_k=2):\n",
    "    \"\"\"ä½¿ç”¨å‘é‡ç´¢å¼• (Sentence Transformer) æ£€ç´¢ä¸Šä¸‹æ–‡\"\"\"\n",
    "    query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "    \n",
    "    # ä½¿ç”¨ torch è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "    scores = torch.nn.functional.cosine_similarity(\n",
    "        query_embedding.unsqueeze(0), corpus_embeddings, dim=1\n",
    "    ).cpu().numpy()\n",
    "\n",
    "    top_k_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    return [corpus[i] for i in top_k_indices if scores[i] > 0]\n",
    "\n",
    "# 3. æ„å»ºå¯¹æ¯”æµ‹è¯•æ•°æ®é›†\n",
    "# æˆ‘ä»¬è®¾è®¡ä¸¤ä¸ªé—®é¢˜ï¼šä¸€ä¸ªå…³é”®è¯æ˜ç¡®ï¼Œä¸€ä¸ªåå‘è¯­ä¹‰ã€‚\n",
    "questions = [\n",
    "    \"RAGASæœ‰å“ªäº›è¯„ä¼°æŒ‡æ ‡ï¼Ÿ\", # é—®é¢˜1: å…³é”®è¯\"RAGAS\"å’Œ\"æŒ‡æ ‡\"å¾ˆæ˜ç¡®\n",
    "    \"å¦‚ä½•æ ¹æ®æ„æ€æ‰¾åˆ°ç›¸å…³çš„æ–‡æ¡£ï¼Ÿ\" # é—®é¢˜2: è¯­ä¹‰åŒ–é—®é¢˜ï¼Œæ²¡æœ‰ç›´æ¥çš„å…³é”®è¯\n",
    "]\n",
    "\n",
    "ground_truths = [\n",
    "    \"RAGASæä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ç­”æ¡ˆç›¸å…³æ€§ (Answer Relevance) å’Œä¸Šä¸‹æ–‡ç²¾åº¦ (Context Precision)ã€‚\",\n",
    "    \"è¯­ä¹‰æœç´¢æˆ–å‘é‡ç´¢å¼•å¯ä»¥æ ¹æ®æ–‡æœ¬çš„å«ä¹‰è€Œéç²¾ç¡®å…³é”®è¯æ¥æŸ¥æ‰¾æ–‡æ¡£ã€‚\"\n",
    "]\n",
    "\n",
    "# ä¸ºæ¯ä¸ªé—®é¢˜ç”Ÿæˆä¸¤ç§æ£€ç´¢ç»“æœå’Œå¯¹åº”çš„ç­”æ¡ˆ\n",
    "data_samples = []\n",
    "for i, q in enumerate(questions):\n",
    "    # ä½¿ç”¨å€’æ’ç´¢å¼•\n",
    "    inverted_contexts = retrieve_with_inverted_index(q)\n",
    "    # ä½¿ç”¨å‘é‡ç´¢å¼•\n",
    "    vector_contexts = retrieve_with_vector_index(q)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿç”Ÿæˆå™¨åŸºäºä¸åŒä¸Šä¸‹æ–‡ç”Ÿæˆçš„ç­”æ¡ˆ\n",
    "    inverted_answer = f\"æ ¹æ®å…³é”®è¯æ£€ç´¢ï¼ŒRAGASçš„æŒ‡æ ‡åŒ…æ‹¬ï¼š{inverted_contexts[0]}\" if inverted_contexts else \"æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚\"\n",
    "    vector_answer = f\"æ ¹æ®è¯­ä¹‰ç†è§£ï¼Œè¦é€šè¿‡æ„æ€æ‰¾åˆ°æ–‡æ¡£ï¼Œå¯ä»¥ä½¿ç”¨å‘é‡ç´¢å¼•å’Œè¯­ä¹‰æœç´¢ã€‚ç›¸å…³ä¿¡æ¯ï¼š{vector_contexts[0]}\" if vector_contexts else \"æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚\"\n",
    "\n",
    "    # å°†å€’æ’ç´¢å¼•çš„ç»“æœæ·»åŠ åˆ°æ•°æ®é›†\n",
    "    data_samples.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": inverted_contexts,\n",
    "        \"answer\": inverted_answer,\n",
    "        \"ground_truth\": ground_truths[i],\n",
    "        \"retrieval_method\": \"Inverted Index\"\n",
    "    })\n",
    "    \n",
    "    # å°†å‘é‡ç´¢å¼•çš„ç»“æœæ·»åŠ åˆ°æ•°æ®é›†\n",
    "    data_samples.append({\n",
    "        \"question\": q,\n",
    "        \"contexts\": vector_contexts,\n",
    "        \"answer\": vector_answer,\n",
    "        \"ground_truth\": ground_truths[i],\n",
    "        \"retrieval_method\": \"Vector Index\"\n",
    "    })\n",
    "\n",
    "# è½¬æ¢ä¸º Hugging Face Dataset\n",
    "dataset = Dataset.from_list(data_samples)\n",
    "\n",
    "# 4. æ‰§è¡Œè¯„ä¼°\n",
    "# æ³¨æ„ï¼šRagasçš„è¯„ä¼°ä¹Ÿä¾èµ–å¤§è¯­è¨€æ¨¡å‹ï¼Œè¯·ç¡®ä¿ä½ å·²é…ç½®å¥½ç›¸åº”çš„API Key (å¦‚OpenAI)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        context_precision, # ä¸Šä¸‹æ–‡ç²¾åº¦: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ä¸é—®é¢˜çš„ç›¸å…³åº¦\n",
    "        context_recall,    # ä¸Šä¸‹æ–‡å¬å›ç‡: æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ˜¯å¦è¦†ç›–äº†çœŸå®ç­”æ¡ˆ\n",
    "        faithfulness,      # å¿ å®åº¦: ç­”æ¡ˆæ˜¯å¦å¿ å®äºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡\n",
    "        answer_relevancy,  # ç­”æ¡ˆç›¸å…³æ€§: ç­”æ¡ˆä¸é—®é¢˜çš„ç›¸å…³åº¦\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 5. æ‰“å°å’Œåˆ†æç»“æœ\n",
    "# è·å– Ragas çš„è¯„ä¼°ç»“æœ\n",
    "df_metrics = result.to_pandas()\n",
    "\n",
    "# æå–åŸå§‹æ•°æ®ä¸­çš„å…ƒä¿¡æ¯ï¼ˆå¦‚ retrieval_methodã€question ç­‰ï¼‰\n",
    "df_original = pd.DataFrame(data_samples)\n",
    "\n",
    "# åˆå¹¶ä¸¤ä¸ª DataFrameï¼ˆæŒ‰è¡Œç´¢å¼•ï¼‰\n",
    "df_combined = pd.concat([df_original.reset_index(drop=True), df_metrics.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# æ‰“å°éœ€è¦çš„åˆ—\n",
    "print(df_combined[[\n",
    "    \"retrieval_method\", \"question\", \n",
    "    \"context_precision\", \"context_recall\", \n",
    "    \"faithfulness\", \"answer_relevancy\"\n",
    "]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe96e9",
   "metadata": {},
   "source": [
    "| æŒ‡æ ‡                | å€’æ’ç´¢å¼•ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰ | å‘é‡ç´¢å¼•ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰ | è¯´æ˜                                   |\n",
    "|---------------------|------------------------|----------------------|----------------------------------------|\n",
    "| context_precision   | å·®                     | å¥½                   | å‘é‡ç´¢å¼•èƒ½æ›´ç²¾å‡†åœ°æ£€ç´¢ç›¸å…³ä¸Šä¸‹æ–‡       |\n",
    "| context_recall      | å·®                     | å¥½                   | å‘é‡ç´¢å¼•èƒ½è¦†ç›–ç­”æ¡ˆæ‰€éœ€ä¿¡æ¯             |\n",
    "| faithfulness        | å·®                     | ä¸­ç­‰                 | å‘é‡ç´¢å¼•ç”Ÿæˆçš„ç­”æ¡ˆæ›´å¿ å®äºä¸Šä¸‹æ–‡       |\n",
    "| answer_relevancy    | å·®                     | å¥½                   | å‘é‡ç´¢å¼•ç”Ÿæˆçš„ç­”æ¡ˆæ›´è´´åˆé—®é¢˜æ„å›¾       |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16717df",
   "metadata": {},
   "source": [
    "### 3.4 è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®\n",
    "\n",
    "- æ‰©å¤§æµ‹è¯•æ•°æ®é›† ï¼šå¢åŠ æ›´å¤šé—®é¢˜ï¼ŒéªŒè¯æ³›åŒ–èƒ½åŠ›ã€‚\n",
    "- è°ƒæ•´ top_k æ£€ç´¢æ•°é‡ ï¼šå°è¯•ä¸åŒ top_k å€¼çœ‹æ˜¯å¦å½±å“è¯„ä¼°ç»“æœã€‚\n",
    "- ä½¿ç”¨æ›´å¼ºå¤§çš„åµŒå…¥æ¨¡å‹ ï¼šå¦‚ BAAI/bge-large-en-v1.5 ç­‰ã€‚\n",
    "- å¯è§†åŒ–ç»“æœå¯¹æ¯” ï¼šç”¨æŸ±çŠ¶å›¾æˆ–é›·è¾¾å›¾å¯¹æ¯”ä¸åŒæ–¹æ³•åœ¨å„é¡¹æŒ‡æ ‡ä¸Šçš„è¡¨ç°ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58b605",
   "metadata": {},
   "source": [
    "## å››ã€å¦‚ä½•ç§‘å­¦è®¾ç½®åˆ‡ç‰‡é•¿åº¦ä¸æ»‘åŠ¨çª—å£ï¼Ÿ\n",
    "### 4.1 åˆ‡ç‰‡é•¿åº¦çš„å½±å“\n",
    "- è¿‡çŸ­ ï¼šä¿¡æ¯ä¸å®Œæ•´ï¼Œå½±å“è¯­ä¹‰è¡¨è¾¾\n",
    "- è¿‡é•¿ ï¼šæ£€ç´¢æ•ˆç‡ä½ï¼Œå½±å“ç”Ÿæˆé€Ÿåº¦\n",
    "\n",
    "### 4.2 æ»‘åŠ¨çª—å£çš„ä½œç”¨\n",
    "- é¿å…ä¸Šä¸‹æ–‡å‰²è£‚\n",
    "- æå‡è¯­ä¹‰è¿ç»­æ€§\n",
    "### 4.3 å®æˆ˜ä»£ç ï¼šè‡ªåŠ¨æµ‹è¯•ä¸åŒåˆ‡ç‰‡ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2144e8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92e69e542824c219eed489fc9b8e31a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c3bbf203a24a6aa83c63b2baa8bea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b24923efdb42bf92829a924a1b2e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7250c2fb4ec742db8af30c1f83507d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ec9c0da9364b5f944138f70a6f213f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fb59be8cf44c74a8763142b39a478c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c431d283cc4f60afa464d1fb7bffe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4273f7ba44ea437b9c9075daaa159c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49ed4d2beb5344ad9c4d7ebd09192ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   answer_relevancy  context_precision  context_recall  faithfulness  \\\n",
      "0          0.876650                1.0             1.0           1.0   \n",
      "1          0.876329                1.0             1.0           1.0   \n",
      "2          0.876574                1.0             1.0           1.0   \n",
      "3          0.876574                1.0             1.0           1.0   \n",
      "4          0.876650                1.0             1.0           1.0   \n",
      "5          0.876329                1.0             1.0           1.0   \n",
      "6          0.876574                1.0             1.0           1.0   \n",
      "7          0.876574                1.0             1.0           1.0   \n",
      "8          0.876650                1.0             1.0           1.0   \n",
      "\n",
      "   chunk_size  chunk_overlap  \n",
      "0         100             20  \n",
      "1         100             50  \n",
      "2         100            100  \n",
      "3         200             20  \n",
      "4         200             50  \n",
      "5         200            100  \n",
      "6         300             20  \n",
      "7         300             50  \n",
      "8         300            100  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import answer_relevancy, context_precision, context_recall, faithfulness\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# æ¨¡æ‹Ÿæ–‡æ¡£å†…å®¹\n",
    "text = \"\"\"\n",
    "RAGAS æä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ Answer Relevanceã€Context Precision ç­‰ã€‚\n",
    "åˆ‡ç‰‡é•¿åº¦å’Œæ»‘åŠ¨çª—å£é…ç½®å¯¹æ£€ç´¢æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚\n",
    "å¯ä»¥é€šè¿‡å®éªŒå¯¹æ¯”ä¸åŒåˆ‡ç‰‡ç­–ç•¥ï¼Œé€‰æ‹©æœ€ä¼˜é…ç½®ã€‚\n",
    "\"\"\"\n",
    "\n",
    "# åˆ‡ç‰‡å‡½æ•°\n",
    "def chunk_text(text, chunk_size=200, chunk_overlap=50):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\", \".\", \" \"]\n",
    "    )\n",
    "    return splitter.split_text(text)\n",
    "\n",
    "# æµ‹è¯•ä¸åŒåˆ‡ç‰‡ç­–ç•¥\n",
    "def test_chunking_strategy(text, chunk_sizes=[100, 200, 300], chunk_overlaps=[20, 50, 100]):\n",
    "    results = []\n",
    "\n",
    "    for size in chunk_sizes:\n",
    "        for overlap in chunk_overlaps:\n",
    "            chunks = chunk_text(text, size, overlap)\n",
    "\n",
    "            # æ„é€ æ•°æ®é›†\n",
    "            data = {\n",
    "                \"question\": [\"RAG ç³»ç»Ÿå¦‚ä½•ä¼˜åŒ–åˆ‡ç‰‡ç­–ç•¥ï¼Ÿ\"],\n",
    "                \"answer\": [\"å¯ä»¥é€šè¿‡ RAGAS æµ‹è¯„å·¥å…·è¯„ä¼°ä¸åŒåˆ‡ç‰‡ç­–ç•¥çš„æ€§èƒ½ï¼Œä¼˜åŒ–åˆ‡ç‰‡é•¿åº¦å’Œæ»‘åŠ¨çª—å£é…ç½®ã€‚\"],\n",
    "                \"contexts\": [chunks],\n",
    "                \"ground_truth\": [\"RAGAS æä¾›äº†å¤šç§è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚ Answer Relevanceã€Context Precision ç­‰ã€‚åˆ‡ç‰‡é•¿åº¦å’Œæ»‘åŠ¨çª—å£é…ç½®å¯¹æ£€ç´¢æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚\"]\n",
    "            }\n",
    "\n",
    "            # è½¬æ¢ä¸º Dataset æ ¼å¼\n",
    "            dataset = Dataset.from_pandas(pd.DataFrame(data))\n",
    "\n",
    "            # è¯„ä¼°\n",
    "            result = evaluate(dataset, metrics=[\n",
    "                answer_relevancy, context_precision, context_recall, faithfulness\n",
    "            ])\n",
    "\n",
    "            # è½¬æ¢ä¸º DataFrame å¹¶æ·»åŠ  chunk é…ç½®ä¿¡æ¯\n",
    "            result_df = result.to_pandas()\n",
    "            result_df[\"chunk_size\"] = size\n",
    "            result_df[\"chunk_overlap\"] = overlap\n",
    "\n",
    "            results.append(result_df)\n",
    "\n",
    "    # åˆå¹¶æ‰€æœ‰ç»“æœ\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "# æ‰§è¡Œæµ‹è¯•\n",
    "results_df = test_chunking_strategy(text)\n",
    "\n",
    "# é‡å‘½ååˆ—ï¼ˆå¯é€‰ï¼‰\n",
    "results_df = results_df.rename(columns={\n",
    "    \"answer_relevancy\": \"answer_relevancy\",\n",
    "    \"context_precision\": \"context_precision\",\n",
    "    \"context_recall\": \"context_recall\",\n",
    "    \"faithfulness\": \"faithfulness\"\n",
    "})\n",
    "\n",
    "# è¾“å‡ºç»“æœ\n",
    "print(results_df[[\n",
    "    \"answer_relevancy\", \"context_precision\", \"context_recall\", \"faithfulness\",\n",
    "    \"chunk_size\", \"chunk_overlap\"\n",
    "]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdc3743",
   "metadata": {},
   "source": [
    "ä»æ•°æ®å¯ä»¥çœ‹å‡ºï¼š\n",
    "- æ‰€æœ‰åˆ‡ç‰‡ç­–ç•¥ä¸‹ï¼Œcontext_precisionã€context_recall å’Œ faithfulness å‡ä¸ºæ»¡åˆ†ï¼ˆ1.0ï¼‰ï¼Œè¯´æ˜æ— è®ºé‡‡ç”¨å“ªç§ chunk_size å’Œ chunk_overlapï¼Œ**æ£€ç´¢ç³»ç»Ÿéƒ½èƒ½å‡†ç¡®æ‰¾åˆ°ç›¸å…³ä¸Šä¸‹æ–‡ï¼Œä¸”ç”Ÿæˆçš„ç­”æ¡ˆå¿ å®äºä¸Šä¸‹æ–‡**ã€‚\n",
    "- answer_relevancy ç•¥æœ‰æ³¢åŠ¨ï¼Œä½†æ•´ä½“å·®å¼‚æå°ï¼ˆä»…åœ¨å°æ•°ç‚¹åå››ä½ï¼‰ï¼Œè¯´æ˜æ‰€æœ‰ç­–ç•¥ç”Ÿæˆçš„ç­”æ¡ˆéƒ½é«˜åº¦ç›¸å…³ã€‚\n",
    "\n",
    "è™½ç„¶ä¸åŒåˆ‡ç‰‡ç­–ç•¥ä¹‹é—´æŒ‡æ ‡å·®å¼‚æå°ï¼Œä½†**chunk_size = 200, chunk_overlap = 50** çš„ç»„åˆåœ¨ answer_relevancy ä¸Šè¡¨ç°æœ€å¥½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4fa672",
   "metadata": {},
   "source": [
    "## äº”ã€æ€»ç»“ï¼šRAG åˆ‡ç‰‡ä¼˜åŒ–çš„ä¸‰å¤§æ ¸å¿ƒåŸåˆ™\n",
    "1. åˆ‡ç‰‡é•¿åº¦ï¼š200 å­—ç¬¦ ï¼Œå…¼é¡¾ä¿¡æ¯å®Œæ•´ä¸æ£€ç´¢æ•ˆç‡\n",
    "2. æ»‘åŠ¨çª—å£ï¼š50 å­—ç¬¦ ï¼Œé¿å…ä¸Šä¸‹æ–‡å‰²è£‚\n",
    "3. ç´¢å¼•ç­–ç•¥ï¼šä¼˜å…ˆä½¿ç”¨å‘é‡ç´¢å¼• ï¼Œæå‡è¯­ä¹‰åŒ¹é…èƒ½åŠ›\n",
    "\n",
    "ğŸš€ è¿›é˜¶å»ºè®®ï¼š æ­å»ºå®Œæ•´çš„ LangChain + RAGAS + LangSmith è¯„ä¼°æµæ°´çº¿ï¼Œå®ç° RAG ç³»ç»Ÿçš„æŒç»­ä¼˜åŒ–ä¸è‡ªåŠ¨åŒ–è°ƒå‚ã€‚ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag50",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
