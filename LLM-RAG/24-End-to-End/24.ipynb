{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c59fbca0",
   "metadata": {},
   "source": [
    "# 金融问答系统生成不准？端到端流程优化提升结果可靠性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bce948",
   "metadata": {},
   "source": [
    "## 1. 为什么我们需要更可靠的金融问答系统？\n",
    "\n",
    "\n",
    "- 金融场景的特殊性：\n",
    "  - 高专业性（ROE、EBITDA、非经损益）\n",
    "  - 高时效性（年报数据不能错年）\n",
    "  - 高风险性（一句错误可能引发合规问题）\n",
    "\n",
    "- 大模型的“幻觉”现实：\n",
    "  - “苹果2023年净利润是999亿美元” → 听起来合理，实为虚构\n",
    "  - 传统 RAG 无法根治：检索→生成→输出，**缺乏验证闭环**\n",
    "\n",
    "- 核心问题：\n",
    "  > “我们能相信模型给出的答案吗？”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5ec12",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. 传统 RAG 的局限性\n",
    "\n",
    "| 传统 RAG 流程 | 问题 |\n",
    "|---------------|------|\n",
    "| 单次检索 → 单次生成 → 直接输出 |  无纠错机制 |\n",
    "| 依赖模型“自觉”引用原文 |  幻觉无法拦截 |\n",
    "| 流程不可见、不可控 |  难以调试与优化 |\n",
    "| 无评估、无 trace |  无法持续迭代 |\n",
    "\n",
    "> **RAG 不是终点，而是起点**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4d73d",
   "metadata": {},
   "source": [
    "## 3. 我们的答案：将 AI 推理变为可编程工作流\n",
    "\n",
    "- 核心理念：\n",
    "  > **AI 推理 ≠ 黑盒输出，而应是可编程、可干预、可验证的决策流程**\n",
    "\n",
    "- 类比：医生问诊流程\n",
    "  - 问诊 → 检查 → 初步诊断 → 验证 → 复查\n",
    "  - 我们的系统也应如此\n",
    "\n",
    "- 技术选型：**LangGraph**\n",
    "  - LangChain 推出的**状态化工作流引擎**\n",
    "  - 支持条件跳转、循环、重试、状态管理\n",
    "  - 让 AI 拥有“判断力”和“纠错能力”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c6c6bd",
   "metadata": {},
   "source": [
    "## 4. 系统架构设计：六大模块闭环\n",
    "\n",
    "```\n",
    "用户提问\n",
    "   ↓\n",
    "[检索] → FAISS + Sentence Transformers（轻量本地检索）\n",
    "   ↓\n",
    "[生成] → GPT / 微调模型（模拟专业回答）\n",
    "   ↓\n",
    "[验证] → 内容一致性检查（防止幻觉）\n",
    "   ↖______↓______↗\n",
    "         |\n",
    "   [LangGraph] ← 控制流程：错了吗？重试！\n",
    "         ↓\n",
    "   [评估] ← LangSmith（全流程 trace 与评估）\n",
    "         ↓\n",
    "   [服务] ← FastAPI（标准 API 接口）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888367ea",
   "metadata": {},
   "source": [
    "## 5. 核心实现一：轻量级向量检索（FAISS）\n",
    "\n",
    "\n",
    "- 不依赖远程向量库，本地部署即可运行\n",
    "- 代码片段（高亮关键行）：\n",
    "\n",
    "```python\n",
    "embeddings = model.encode(texts)\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "# 检索\n",
    "q_emb = model.encode([query])\n",
    "_, indices = index.search(q_emb, 3)\n",
    "```\n",
    "\n",
    "- 优势：\n",
    "  - 轻量、快速、支持中文\n",
    "  - 可增量更新，适合企业私有化部署"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e680d47",
   "metadata": {},
   "source": [
    "## 6. 核心实现二：LangGraph 编排闭环流程\n",
    "\n",
    "- 流程图：\n",
    "  ```\n",
    "  [检索] → [生成] → [验证]\n",
    "                   ↓\n",
    "              是？ → END\n",
    "              否？ → 重试检索\n",
    "  ```\n",
    "\n",
    "- 关键代码：决策逻辑\n",
    "\n",
    "```python\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, List, Dict\n",
    "from retrieval.vector_store import VectorRetriever\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# 初始化组件\n",
    "retriever = VectorRetriever(\"data/financial_docs.jsonl\")\n",
    "llm_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# 定义工作流状态\n",
    "class GraphState(TypedDict):\n",
    "    question: str\n",
    "    retrieved_docs: List[Dict]\n",
    "    generation: str\n",
    "    attempts: int\n",
    "    verified: bool\n",
    "\n",
    "# 节点1：检索\n",
    "def retrieve(state: GraphState):\n",
    "    docs = retriever.retrieve(state[\"question\"])\n",
    "    return {**state, \"retrieved_docs\": docs}\n",
    "\n",
    "# 节点2：生成\n",
    "def generate(state: GraphState):\n",
    "    context = \"\\n\".join([doc[\"text\"] for doc in state[\"retrieved_docs\"]])\n",
    "    prompt = f\"\"\"\n",
    "    请根据以下真实资料回答问题。若信息不足，请回答“无法确定”。\n",
    "    资料：{context}\n",
    "    问题：{state['question']}\n",
    "    \"\"\"\n",
    "    response = llm_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2\n",
    "    )\n",
    "    return {**state, \"generation\": response.choices[0].message.content}\n",
    "\n",
    "# 节点3：验证（防止幻觉）\n",
    "def verify(state: GraphState):\n",
    "    gen = state[\"generation\"]\n",
    "    # 检查生成答案是否包含任一原文片段\n",
    "    matched = any(\n",
    "        doc[\"text\"].strip() in gen\n",
    "        for doc in state[\"retrieved_docs\"]\n",
    "        if len(doc[\"text\"].strip()) > 10\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"verified\": matched,\n",
    "        \"attempts\": state.get(\"attempts\", 0) + 1\n",
    "    }\n",
    "\n",
    "# 决策函数：是否需要重试？\n",
    "def should_retry(state: GraphState):\n",
    "    if state[\"verified\"] or state[\"attempts\"] >= 2:\n",
    "        return \"end\"\n",
    "    return \"retrieve\"  # 可扩展为 rewrite 后重检\n",
    "# 构建图\n",
    "def create_rag_graph():\n",
    "    workflow = StateGraph(GraphState)\n",
    "    workflow.add_node(\"retrieve\", retrieve)\n",
    "    workflow.add_node(\"generate\", generate)\n",
    "    workflow.add_node(\"verify\", verify)\n",
    "\n",
    "    workflow.set_entry_point(\"retrieve\")\n",
    "    workflow.add_edge(\"retrieve\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", \"verify\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"verify\",\n",
    "        should_retry,\n",
    "        {\"end\": END, \"retrieve\": \"retrieve\"}\n",
    "    )\n",
    "    return workflow.compile()\n",
    "```\n",
    "\n",
    "- 优势：\n",
    "  - 支持多跳推理\n",
    "  - 可扩展为 query rewrite、多源检索等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1039d0cb",
   "metadata": {},
   "source": [
    "## 7. 核心实现三：验证机制防止幻觉\n",
    "\n",
    "\n",
    "- 验证逻辑：\n",
    "  - 检查生成答案是否包含原文片段\n",
    "  - 简单但有效，拦截 80%+ 明显幻觉\n",
    "\n",
    "```python\n",
    "matched = any(doc[\"text\"].strip() in generation for doc in docs)\n",
    "```\n",
    "\n",
    "- 进阶方向：\n",
    "  - NLI 模型判断蕴含关系\n",
    "  - 数字提取比对（如净利润）\n",
    "  - 用户反馈打标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e725d7",
   "metadata": {},
   "source": [
    "## 8. 核心实现四：FastAPI 服务化部署\n",
    "\n",
    "- 提供标准 RESTful 接口：\n",
    "\n",
    "```bash\n",
    "curl -X POST http://localhost:8000/qa \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"question\": \"苹果公司2023年的净利润是多少？\"}'\n",
    "```\n",
    "\n",
    "执行预测，返回预测结果\n",
    "```python\n",
    "# api/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import JSONResponse\n",
    "from graph.rag_workflow import create_rag_graph\n",
    "import asyncio\n",
    "\n",
    "app = FastAPI(title=\"金融问答系统\")\n",
    "rag_app = create_rag_graph()\n",
    "\n",
    "@app.post(\"/qa\")\n",
    "async def question_answering(request: Request):\n",
    "    data = await request.json()\n",
    "    question = data.get(\"question\", \"\").strip()\n",
    "    if not question:\n",
    "        return JSONResponse({\"error\": \"缺少问题\"}, status_code=400)\n",
    "\n",
    "    # 同步调用 LangGraph（生产环境建议异步）\n",
    "    input_state = {\"question\": question, \"attempts\": 0, \"verified\": False}\n",
    "    loop = asyncio.get_event_loop()\n",
    "    result = await loop.run_in_executor(None, lambda: rag_app.invoke(input_state))\n",
    "\n",
    "    return JSONResponse({\n",
    "        \"answer\": result[\"generation\"],\n",
    "        \"sources\": [doc[\"meta\"] for doc in result[\"retrieved_docs\"]],\n",
    "        \"verified\": result[\"verified\"],\n",
    "        \"attempts\": result[\"attempts\"]\n",
    "    })\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"message\": \"金融问答系统运行中\", \"endpoints\": [\"/qa (POST)\"]}\n",
    "```\n",
    "\n",
    "- 返回结构化结果：\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"answer\": \"998亿美元\",\n",
    "  \"sources\": [{\"company\": \"Apple\", \"year\": 2023, ...}],\n",
    "  \"verified\": true\n",
    "}\n",
    "```\n",
    "\n",
    "- 优势：易于集成到客服、投研、合规系统\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afbbc89",
   "metadata": {},
   "source": [
    "## 9. 全流程可观测：LangSmith 监控与评估\n",
    "\n",
    "\n",
    "- LangSmith 能做什么？\n",
    "  - 自动记录每一次调用的完整 trace\n",
    "  - 查看检索内容、prompt、生成结果\n",
    "  - 分析耗时瓶颈（检索 vs 生成）\n",
    "  - 添加自定义评估指标（FactScore、相关性）\n",
    "  - A/B 测试不同策略\n",
    "\n",
    "![langsmith1](24/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abb58f",
   "metadata": {},
   "source": [
    "## 10. 工程化价值总结\n",
    "\n",
    "\n",
    "| 维度 | 本方案优势 |\n",
    "|------|-----------|\n",
    "| **可靠性** | 验证+重试，显著降低幻觉 |\n",
    "| **可解释性** | 答案来源可追溯 |\n",
    "| **可控性** | 流程可编程、可干预 |\n",
    "| **可评估性** | LangSmith 全链路监控 |\n",
    "| **可部署性** | FastAPI 标准服务 |\n",
    "| **可迭代性** | 支持反馈驱动优化 |\n",
    "\n",
    "> 这不是一个 Demo，而是一个 **可交付的工程系统**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffed9d64",
   "metadata": {},
   "source": [
    "## 结论与展望\n",
    "\n",
    "\n",
    "- **结论**：\n",
    "  > 在金融AI中，**可信比智能更重要**。  \n",
    "  > 可靠的系统，必须建立在**工程化、流程化、可评估**的基础之上。\n",
    "\n",
    "- **未来方向**：\n",
    "  - 加入 Query Rewrite 提升召回\n",
    "  - 使用 LoRA 微调模型，降低成本依赖\n",
    "  - 支持 PDF 表格解析（财报结构化）\n",
    "  - 构建用户反馈闭环，驱动持续优化\n",
    "\n",
    "- **一句话总结**：\n",
    "  > **我们不追求“一次生成就正确”，而是追求“即使错了也能发现并纠正”。**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
